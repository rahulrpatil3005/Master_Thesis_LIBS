{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91449d85-7d3b-43c5-a75e-7d440c448a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5ede7d-a980-4f35-ba9d-e9c3e58bd2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.pyplot as plt1 \n",
    "\n",
    "import statistics\n",
    "import os\n",
    "\n",
    "###############################################\n",
    "from peakutils import indexes\n",
    "from peakutils import baseline\n",
    "from scipy.signal import find_peaks as fp\n",
    "from scipy.signal import  peak_widths\n",
    "\n",
    "from scipy.signal import savgol_filter \n",
    "\n",
    "###############################################\n",
    "from bokeh.plotting import figure , show\n",
    "from pybaselines import whittaker as pl\n",
    "\n",
    "\n",
    "\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29f291f-291c-4ffc-b74a-eb28f47e4ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder_path):\n",
    "    # List to store DataFrames for intensity columns\n",
    "    intensity_dfs = []\n",
    "\n",
    "    # List to store file names\n",
    "    file_names = []\n",
    "\n",
    "    # Get a list of .txt files in the folder\n",
    "    txt_files = [file_name for file_name in os.listdir(folder_path) if file_name.endswith('.txt')]\n",
    "\n",
    "    # Sort the .txt files based on their numerical order\n",
    "    # txt_files.sort(key=lambda x: int(re.search(r'_(\\d+)\\.txt', x).group(1)))\n",
    "\n",
    "    # Read the wavelength values from the first file\n",
    "    first_file_path = os.path.join(folder_path, txt_files[0])\n",
    "    wavelength_df = pd.read_csv(first_file_path, header=None, delimiter=';', usecols=[0], names=['wavelength'])\n",
    "\n",
    "    # Loop through each file in ascending order\n",
    "    for file_name in txt_files:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Read intensity values from each file into a DataFrame\n",
    "        intensity_df = pd.read_csv(file_path, header=None, delimiter=';', usecols=[1], names=['intensity'])\n",
    "        \n",
    "        # Store intensity DataFrame\n",
    "        intensity_dfs.append(intensity_df)\n",
    "        \n",
    "        # Store file name\n",
    "        file_names.append(os.path.splitext(file_name)[0])\n",
    "\n",
    "    # Concatenate intensity DataFrames\n",
    "    result_df = pd.concat(intensity_dfs, axis=1)\n",
    "\n",
    "    # Add the wavelength column to the result DataFrame\n",
    "    result_df = pd.concat([wavelength_df, result_df], axis=1)\n",
    "\n",
    "    # Rename the columns with file names\n",
    "    result_df.columns = ['wavelength'] + file_names\n",
    "\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7413dbf-dcfa-463a-9778-38bbb6c50536",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE1_Raw_df = load_data('Batch_2/sample_1')\n",
    "###################################################\n",
    "SAMPLE2_Raw_df = load_data('Batch_2/sample_2')\n",
    "###################################################\n",
    "SAMPLE3_Raw_df = load_data('Batch_2/sample_3')\n",
    "###################################################\n",
    "SAMPLE4_Raw_df = load_data('Batch_2/sample_4')\n",
    "###################################################\n",
    "SAMPLE5_Raw_df = load_data('Batch_2/sample_5')\n",
    "###################################################\n",
    "SAMPLE6_Raw_df = load_data('Batch_2/sample_6')\n",
    "###################################################\n",
    "SAMPLE7_Raw_df = load_data('Batch_2/sample_7')\n",
    "####################################################\n",
    "SAMPLE8_Raw_df = load_data('Batch_2/sample_8')\n",
    "####################################################\n",
    "SAMPLE9_Raw_df = load_data('Batch_3/sample_9')\n",
    "####################################################\n",
    "SAMPLE10_Raw_df = load_data('Batch_3/sample_10')\n",
    "####################################################\n",
    "SAMPLE11_Raw_df = load_data('Batch_3/sample_11')\n",
    "####################################################\n",
    "SAMPLE12_Raw_df = load_data('Batch_3/sample_12')\n",
    "####################################################\n",
    "SAMPLE13_Raw_df = load_data('Batch_3/sample_13')\n",
    "####################################################\n",
    "SAMPLE14_Raw_df = load_data('Batch_3/sample_14')\n",
    "####################################################\n",
    "SAMPLE15_Raw_df = load_data('Batch_3/sample_15')\n",
    "####################################################\n",
    "SAMPLE16_Raw_df = load_data('Batch_3/sample_16')\n",
    "####################################################\n",
    "SAMPLE17_Raw_df = load_data('Batch_3/sample_17')\n",
    "####################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9dffba-c27f-4873-b2d7-833aff40f8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming you have dataframes named SAMPLE1_Raw_df, SAMPLE2_Raw_df, etc.\n",
    "# Store them in a dictionary\n",
    "datafram = {\n",
    "    1: SAMPLE1_Raw_df,\n",
    "    2: SAMPLE2_Raw_df,\n",
    "    3: SAMPLE3_Raw_df,\n",
    "    4: SAMPLE4_Raw_df,\n",
    "    5: SAMPLE5_Raw_df,\n",
    "    6: SAMPLE6_Raw_df,\n",
    "    7: SAMPLE7_Raw_df,\n",
    "    8: SAMPLE8_Raw_df,\n",
    "    9: SAMPLE9_Raw_df,\n",
    "    10: SAMPLE10_Raw_df,\n",
    "    11: SAMPLE11_Raw_df,\n",
    "    12: SAMPLE12_Raw_df,\n",
    "    13: SAMPLE13_Raw_df,\n",
    "    14: SAMPLE14_Raw_df,\n",
    "    15: SAMPLE15_Raw_df,\n",
    "    16: SAMPLE16_Raw_df,\n",
    "    17: SAMPLE17_Raw_df,   \n",
    "    # Add entries for other samples\n",
    "}\n",
    "\n",
    "# Define the sample number you want to process\n",
    "sample_number = 2 # Replace with any sample number (e.g., 3, 4, ..., 17)\n",
    "\n",
    "# Get the dataframe for the specified sample number\n",
    "df_sample = datafram[sample_number]\n",
    "\n",
    "# Construct the column name based on the sample number\n",
    "column_name = f'sample{sample_number}_6'\n",
    "\n",
    "# Filter the dataframe to get the noise list\n",
    "noise_list = df_sample.loc[df_sample['wavelength'] < 215.0, column_name]\n",
    "\n",
    "# Calculate the RMS intensity noise\n",
    "RMS_intensity_noise = np.sqrt(np.mean((noise_list)**2))\n",
    "\n",
    "# Print the RMS intensity noise\n",
    "print(RMS_intensity_noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e1740e-9a99-4996-a033-cf8e3dcfe4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #METHOD  - Scipy\n",
    "\n",
    "# Threshold = 20 #(Noise Intensity * Threshold) Value for signal filtering\n",
    "# height_2 = None\n",
    "# Peak_Prominenace = (Threshold * RMS_intensity_noise) # #Uses S/N ratio , as comapred to other peaks\n",
    "# minimum_distance_3 = None   #minimum distance between two peaks\n",
    "\n",
    "# Sample_Peak, info = fp(SAMPLE2_Raw_df.sample2_6,height=height_2,prominence=Peak_Prominenace,distance=minimum_distance_3,width=0.1)\n",
    "\n",
    "\n",
    "# Selected_Sample_Spectra = SAMPLE2_Raw_df.iloc[Sample_Peak] \n",
    "\n",
    "# Sample_Spectra_Peaks = figure(title = 'Peaks in hLIBS Spectra', x_axis_label = 'Wavelength' , y_axis_label = 'Intensity')\n",
    "# Sample_Spectra_Peaks.line(SAMPLE2_Raw_df.wavelength,SAMPLE2_Raw_df.sample2_6 , line_width = 2, color =\"green\" )\n",
    "# Sample_Spectra_Peaks.circle(Selected_Sample_Spectra.wavelength , Selected_Sample_Spectra.sample2_6 , color = 'red' , size = 8)\n",
    "\n",
    "# Sample_Spectra_Peaks.width = 1200\n",
    "# Sample_Spectra_Peaks.height = 600\n",
    "\n",
    "# print(Selected_Sample_Spectra)\n",
    "# show(Sample_Spectra_Peaks)\n",
    "\n",
    "\n",
    "# Define the threshold and other parameters for peak finding\n",
    "Threshold = 6  # (Noise Intensity * Threshold) Value for signal filtering\n",
    "height_2 = None\n",
    "Peak_Prominenace = (Threshold * RMS_intensity_noise)  # Uses S/N ratio, as compared to other peaks\n",
    "minimum_distance_3 = None  # Minimum distance between two peaks\n",
    "\n",
    "# Find the peaks\n",
    "Sample_Peak, info = fp(df_sample[column_name], height=height_2, prominence=Peak_Prominenace, distance=minimum_distance_3, width=0.1)\n",
    "\n",
    "# Select the sample spectra\n",
    "Selected_Sample_Spectra = df_sample.iloc[Sample_Peak]\n",
    "\n",
    "# Create the plot\n",
    "Sample_Spectra_Peaks = figure(title='Peaks in hLIBS Spectra', x_axis_label='Wavelength', y_axis_label='Intensity')\n",
    "Sample_Spectra_Peaks.line(df_sample['wavelength'], df_sample[column_name], line_width=2, color=\"green\")\n",
    "Sample_Spectra_Peaks.circle(Selected_Sample_Spectra['wavelength'], Selected_Sample_Spectra[column_name], color='red', size=5)\n",
    "\n",
    "Sample_Spectra_Peaks.width = 1200\n",
    "Sample_Spectra_Peaks.height = 600\n",
    "\n",
    "# Print the selected sample spectra\n",
    "print(Selected_Sample_Spectra)\n",
    "\n",
    "# Show the plot\n",
    "show(Sample_Spectra_Peaks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e292b8-ef9e-4bf2-9475-b3d325fde3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peak Selection and Data Trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f82e7b-7329-40c8-8497-ad54f2bc9f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# peak = 500.606\n",
    "# peak_min = (peak - 5) \n",
    "# peak_max = (peak + 5) \n",
    "\n",
    "#Getting the full wavelength\n",
    "Wavelength_Min = 200.041162\n",
    "Wavelength_Max = 963.333130\n",
    "\n",
    "\n",
    "SAMPLE1_Select_df = SAMPLE1_Raw_df[(SAMPLE1_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE1_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE2_Select_df = SAMPLE2_Raw_df[(SAMPLE2_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE2_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE3_Select_df = SAMPLE3_Raw_df[(SAMPLE3_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE3_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE4_Select_df = SAMPLE4_Raw_df[(SAMPLE4_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE4_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE5_Select_df = SAMPLE5_Raw_df[(SAMPLE5_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE5_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE6_Select_df = SAMPLE6_Raw_df[(SAMPLE6_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE6_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE7_Select_df = SAMPLE7_Raw_df[(SAMPLE7_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE7_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE8_Select_df = SAMPLE8_Raw_df[(SAMPLE8_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE8_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE9_Select_df = SAMPLE9_Raw_df[(SAMPLE9_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE9_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE10_Select_df = SAMPLE10_Raw_df[(SAMPLE10_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE10_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE11_Select_df = SAMPLE11_Raw_df[(SAMPLE11_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE11_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE12_Select_df = SAMPLE12_Raw_df[(SAMPLE12_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE12_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE13_Select_df = SAMPLE13_Raw_df[(SAMPLE13_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE13_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE14_Select_df = SAMPLE14_Raw_df[(SAMPLE14_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE14_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE15_Select_df = SAMPLE15_Raw_df[(SAMPLE15_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE15_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE16_Select_df = SAMPLE16_Raw_df[(SAMPLE16_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE16_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE17_Select_df = SAMPLE17_Raw_df[(SAMPLE17_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE17_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "SAMPLE17_Select_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2989c9d-e056-4f32-a037-644f66022d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "Selected_df_Plot = figure(title = 'Selected Data Plot' , x_axis_label = 'Wavelength' , y_axis_label = 'Intensity')\n",
    "\n",
    "Selected_df_Plot.line(SAMPLE1_Select_df.wavelength,SAMPLE1_Select_df.sample1_6 , line_width = 2, color =\"blue\" )\n",
    "#####################################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE2_Select_df.wavelength,SAMPLE2_Select_df.sample2_6 , line_width = 2, color =\"orange\" )\n",
    "###############################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE3_Select_df.wavelength,SAMPLE3_Select_df.sample3_6 , line_width = 2, color =\"green\")\n",
    "######################################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE4_Select_df.wavelength,SAMPLE4_Select_df.sample4_6 , line_width = 2, color =\"red\")\n",
    "##############################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE5_Select_df.wavelength,SAMPLE5_Select_df.sample5_6 , line_width = 2, color =\"purple\")\n",
    "###############################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE6_Select_df.wavelength,SAMPLE6_Select_df.sample6_6 , line_width = 2, color =\"brown\")\n",
    "####################################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE7_Select_df.wavelength,SAMPLE7_Select_df.sample7_6 , line_width = 2, color =\"pink\")\n",
    "##################################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE8_Select_df.wavelength,SAMPLE8_Select_df.sample8_6 , line_width = 2, color =\"gray\")\n",
    "###################################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE9_Select_df.wavelength,SAMPLE9_Select_df.sample9_6 , line_width = 2, color =\"olive\")\n",
    "###################################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE10_Select_df.wavelength,SAMPLE10_Select_df.sample10_6 , line_width = 2, color =\"Cyan\")\n",
    "###################################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE11_Select_df.wavelength,SAMPLE11_Select_df.sample11_6 , line_width = 2, color =\"black\")\n",
    "###################################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE12_Select_df.wavelength,SAMPLE12_Select_df.sample12_6 , line_width = 2, color =\"tomato\")\n",
    "###################################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE13_Select_df.wavelength,SAMPLE13_Select_df.sample13_6 , line_width = 2, color =\"steelblue\")\n",
    "###################################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE14_Select_df.wavelength,SAMPLE14_Select_df.sample14_6 , line_width = 2, color =\"limegreen\")\n",
    "###################################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE15_Select_df.wavelength,SAMPLE15_Select_df.sample15_6 , line_width = 2, color =\"deeppink\")\n",
    "###################################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE16_Select_df.wavelength,SAMPLE16_Select_df.sample16_6 , line_width = 2, color =\"gold\")\n",
    "###################################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE17_Select_df.wavelength,SAMPLE17_Select_df.sample17_6 , line_width = 2, color =\"indigo\")\n",
    "###################################################################################################################\n",
    "\n",
    "Selected_df_Plot.width = 900\n",
    "Selected_df_Plot.height = 500\n",
    "show(Selected_df_Plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b60fd79-0b20-48c1-b51a-8c679909c4e3",
   "metadata": {},
   "source": [
    "# Data Preprocessing of the Spectra"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7daa1f7b-9943-4849-9239-3e1346fa66e8",
   "metadata": {},
   "source": [
    "The above plot eventhough a spectra , is still a Raw Spectra , which still has lot of Artifects , before proceeding for the Univariate Calibration , its important to Pre Process the Raw Spectra accordingly. Various Pre Processing Techniques could be used here :-\n",
    "\n",
    "1) Baseline Correction - Very Very little background radiation is still present in the spectra, which corresponds to the spectral baseline and imposes difficulties for quantitative elemental analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c84d83-16a4-4deb-a607-28ecbcc13645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_correction(df):\n",
    "    \"\"\"\n",
    "    Perform baseline correction on the intensity columns of the input DataFrame and create a new DataFrame with corrected values.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): Input DataFrame containing the wavelength and intensity columns.\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: New DataFrame with baseline-corrected intensity columns and the same wavelength column as the input DataFrame.\n",
    "    \"\"\"\n",
    "    # Copy the 'wavelength' column from the input DataFrame\n",
    "    new_df = pd.DataFrame({'wavelength': df['wavelength']})\n",
    "    \n",
    "    # Perform baseline correction for each intensity column and add them to the new DataFrame\n",
    "    for col in df.columns[1:]:  # Exclude the 'wavelength' column\n",
    "        baseline, _ = pl.airpls(df[col])\n",
    "        corrected_values = df[col] - baseline\n",
    "        new_df[col] = corrected_values\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9bfa5c-5242-47fe-9e86-0c2cb15f18b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE1_BaselineCorrected_df = baseline_correction(SAMPLE1_Raw_df)\n",
    "SAMPLE2_BaselineCorrected_df = baseline_correction(SAMPLE2_Raw_df)\n",
    "SAMPLE3_BaselineCorrected_df = baseline_correction(SAMPLE3_Raw_df)\n",
    "SAMPLE4_BaselineCorrected_df = baseline_correction(SAMPLE4_Raw_df)\n",
    "SAMPLE5_BaselineCorrected_df = baseline_correction(SAMPLE5_Raw_df)\n",
    "SAMPLE6_BaselineCorrected_df = baseline_correction(SAMPLE6_Raw_df)\n",
    "SAMPLE7_BaselineCorrected_df = baseline_correction(SAMPLE7_Raw_df)\n",
    "SAMPLE8_BaselineCorrected_df = baseline_correction(SAMPLE8_Raw_df)\n",
    "SAMPLE9_BaselineCorrected_df = baseline_correction(SAMPLE9_Raw_df)\n",
    "SAMPLE10_BaselineCorrected_df = baseline_correction(SAMPLE10_Raw_df)\n",
    "SAMPLE11_BaselineCorrected_df = baseline_correction(SAMPLE11_Raw_df)\n",
    "SAMPLE12_BaselineCorrected_df = baseline_correction(SAMPLE12_Raw_df)\n",
    "SAMPLE13_BaselineCorrected_df = baseline_correction(SAMPLE13_Raw_df)\n",
    "SAMPLE14_BaselineCorrected_df = baseline_correction(SAMPLE14_Raw_df)\n",
    "SAMPLE15_BaselineCorrected_df = baseline_correction(SAMPLE15_Raw_df)\n",
    "SAMPLE16_BaselineCorrected_df = baseline_correction(SAMPLE16_Raw_df)\n",
    "SAMPLE17_BaselineCorrected_df = baseline_correction(SAMPLE17_Raw_df)\n",
    "\n",
    "SAMPLE1_BaselineCorrected_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2993e722-bb41-4498-9959-a32327660505",
   "metadata": {},
   "source": [
    "2) Normalization - Its usually noticed that , for a measurement of a similar sample ,there is a lot of scattering in the intensities , this typical artifect is called scattering.\n",
    "\n",
    "For Instance , you could see the plot above , Though this are the plots from the same sample SAMPLE1 , measured on 12 different Areas , its quite visible , for some  spectras , the peak heights or Intensities are not same.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6ce9c0-5d57-4de9-b184-f060d8bd7a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_normal_variate_normalization(df):\n",
    "    # Select columns containing intensities\n",
    "    intensity_cols = df.columns[1:]  #  columns 2 to 13 are intensities and are stored in intensity_cols\n",
    "\n",
    "    # SVN normalization\n",
    "    for col in intensity_cols:\n",
    "        mean_intensity = df[col].mean()\n",
    "        std_intensity = df[col].std()\n",
    "        df[col] = (df[col] - mean_intensity) / std_intensity\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8be05e-79c5-4efc-8a61-51ed1f4f0765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_intensity_normalization(df):\n",
    "    # Selecting only the intensity columns (assuming the first column is wavelength)\n",
    "    intensities = df.iloc[:, 1:]  \n",
    "\n",
    "    # Initialize an empty DataFrame to store normalized intensities\n",
    "    normalized_intensities = pd.DataFrame()\n",
    "\n",
    "    # Iterate over each column (each spectrum)\n",
    "    for column in intensities.columns:\n",
    "        spectrum = intensities[column]\n",
    "        total_intensity = spectrum.sum()\n",
    "        \n",
    "        # Normalize the spectrum by dividing each intensity value by the total intensity\n",
    "        normalized_spectrum = spectrum / total_intensity\n",
    "        \n",
    "        # Append the normalized spectrum to the DataFrame of normalized intensities\n",
    "        normalized_intensities[column] = normalized_spectrum\n",
    "\n",
    "    # Combine the wavelength column with normalized intensities\n",
    "    normalized_df = pd.concat([df.iloc[:, 0], normalized_intensities], axis=1)\n",
    "\n",
    "    return normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8611c770-6615-44fa-8e35-283c6d84bd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_norm_normalization(df):\n",
    "    # Selecting only the intensity columns (assuming the first column is wavelength)\n",
    "    intensities_1 = df.iloc[:, 1:]  \n",
    "    \n",
    "    # Initialize an empty DataFrame to store normalized intensities\n",
    "    normalized_intensities_1 = pd.DataFrame()\n",
    "\n",
    "    # Iterate over each column (each spectrum)\n",
    "    for column_1 in intensities_1.columns:\n",
    "        spectrum_1 = intensities_1[column_1]\n",
    "        \n",
    "        # Calculate the norm of the spectrum using a simple equation\n",
    "        spectrum_norm = np.sqrt(np.sum(spectrum_1 ** 2))\n",
    "        \n",
    "        # Normalize the spectrum by dividing each intensity value by its norm\n",
    "        normalized_spectrum_1 = spectrum_1 / spectrum_norm\n",
    "        \n",
    "        # Assign the normalized spectrum to the DataFrame of normalized intensities\n",
    "        normalized_intensities_1[column_1] = normalized_spectrum_1\n",
    "\n",
    "    # Combine the wavelength column with normalized intensities\n",
    "    normalized_df_1 = pd.concat([df.iloc[:, 0], normalized_intensities_1], axis=1)\n",
    "    \n",
    "    return normalized_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660b150f-85e0-474e-b401-c3f827a91ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_intensity_normalization(df):\n",
    "    # Selecting only the intensity columns (assuming the first column is wavelength)\n",
    "    intensities_2 = df.iloc[:, 1:]  \n",
    "\n",
    "    # Initialize an empty DataFrame to store normalized intensities\n",
    "    normalized_intensities_2 = pd.DataFrame()\n",
    "\n",
    "    # Iterate over each column (each spectrum)\n",
    "    for column_2 in intensities_2.columns:\n",
    "        spectrum_2 = intensities_2[column_2]\n",
    "        \n",
    "        # Find the maximum intensity value in the spectrum\n",
    "        max_intensity = spectrum_2.max()\n",
    "        \n",
    "        # Normalize the spectrum by dividing each intensity value by the maximum intensity\n",
    "        normalized_spectrum_2 = spectrum_2 / max_intensity\n",
    "        \n",
    "        # Assign the normalized spectrum to the DataFrame of normalized intensities\n",
    "        normalized_intensities_2[column_2] = normalized_spectrum_2\n",
    "\n",
    "    # Combine the wavelength column with normalized intensities\n",
    "    normalized_df_2 = pd.concat([df.iloc[:, 0], normalized_intensities_2], axis=1)\n",
    "\n",
    "    return normalized_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9941e737-fe46-4246-84a8-0e7823ac2e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE1_Normalized_df = unit_norm_normalization(SAMPLE1_BaselineCorrected_df)\n",
    "SAMPLE2_Normalized_df = unit_norm_normalization(SAMPLE2_BaselineCorrected_df)\n",
    "SAMPLE3_Normalized_df = unit_norm_normalization(SAMPLE3_BaselineCorrected_df)\n",
    "SAMPLE4_Normalized_df = unit_norm_normalization(SAMPLE4_BaselineCorrected_df)\n",
    "SAMPLE5_Normalized_df = unit_norm_normalization(SAMPLE5_BaselineCorrected_df)\n",
    "SAMPLE6_Normalized_df = unit_norm_normalization(SAMPLE6_BaselineCorrected_df)\n",
    "SAMPLE7_Normalized_df = unit_norm_normalization(SAMPLE7_BaselineCorrected_df)\n",
    "SAMPLE8_Normalized_df = unit_norm_normalization(SAMPLE8_BaselineCorrected_df)\n",
    "SAMPLE9_Normalized_df = unit_norm_normalization(SAMPLE9_BaselineCorrected_df)\n",
    "SAMPLE10_Normalized_df = unit_norm_normalization(SAMPLE10_BaselineCorrected_df)\n",
    "SAMPLE11_Normalized_df = unit_norm_normalization(SAMPLE11_BaselineCorrected_df)\n",
    "SAMPLE12_Normalized_df = unit_norm_normalization(SAMPLE12_BaselineCorrected_df)\n",
    "SAMPLE13_Normalized_df = unit_norm_normalization(SAMPLE13_BaselineCorrected_df)\n",
    "SAMPLE14_Normalized_df = unit_norm_normalization(SAMPLE14_BaselineCorrected_df)\n",
    "SAMPLE15_Normalized_df = unit_norm_normalization(SAMPLE15_BaselineCorrected_df)\n",
    "SAMPLE16_Normalized_df = unit_norm_normalization(SAMPLE16_BaselineCorrected_df)\n",
    "SAMPLE17_Normalized_df = unit_norm_normalization(SAMPLE17_BaselineCorrected_df)\n",
    "\n",
    "SAMPLE1_Normalized_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "76a71a98-8dcb-4e63-8c59-8f2812316074",
   "metadata": {},
   "source": [
    "#Average the Resultant Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938795d0-d16a-494a-b87c-cc3dbe00e022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_intensity(df, intensity_name):\n",
    "    # Select intensity columns (from column 2 to column 13)\n",
    "    intensity_columns = df.columns[1:]\n",
    "\n",
    "    # Calculate the mean of intensity columns\n",
    "    averaged_intensity = df[intensity_columns].mean(axis=1)\n",
    "\n",
    "    # Create a new DataFrame with wavelength and averaged intensity\n",
    "    averaged_df = pd.DataFrame({'wavelength': df['wavelength'], intensity_name: averaged_intensity})\n",
    "\n",
    "    return averaged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08e2bed-971b-4bd8-b8a9-da69c5e1e41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE1_Averaged_df = average_intensity(df = SAMPLE1_Normalized_df , intensity_name= 'sample1')\n",
    "SAMPLE2_Averaged_df = average_intensity(df = SAMPLE2_Normalized_df , intensity_name= 'sample2')\n",
    "SAMPLE3_Averaged_df = average_intensity(df = SAMPLE3_Normalized_df , intensity_name= 'sample3')\n",
    "SAMPLE4_Averaged_df = average_intensity(df = SAMPLE4_Normalized_df , intensity_name= 'sample4')\n",
    "SAMPLE5_Averaged_df = average_intensity(df = SAMPLE5_Normalized_df , intensity_name= 'sample5')\n",
    "SAMPLE6_Averaged_df = average_intensity(df = SAMPLE6_Normalized_df , intensity_name= 'sample6')\n",
    "SAMPLE7_Averaged_df = average_intensity(df = SAMPLE7_Normalized_df , intensity_name= 'sample7')\n",
    "SAMPLE8_Averaged_df = average_intensity(df = SAMPLE8_Normalized_df , intensity_name= 'sample8')\n",
    "SAMPLE9_Averaged_df = average_intensity(df = SAMPLE9_Normalized_df , intensity_name= 'sample9')\n",
    "SAMPLE10_Averaged_df = average_intensity(df = SAMPLE10_Normalized_df , intensity_name= 'sample10')\n",
    "SAMPLE11_Averaged_df = average_intensity(df = SAMPLE11_Normalized_df , intensity_name= 'sample11')\n",
    "SAMPLE12_Averaged_df = average_intensity(df = SAMPLE12_Normalized_df , intensity_name= 'sample12')\n",
    "SAMPLE13_Averaged_df = average_intensity(df = SAMPLE13_Normalized_df , intensity_name= 'sample13')\n",
    "SAMPLE14_Averaged_df = average_intensity(df = SAMPLE14_Normalized_df , intensity_name= 'sample14')\n",
    "SAMPLE15_Averaged_df = average_intensity(df = SAMPLE15_Normalized_df , intensity_name= 'sample15')\n",
    "SAMPLE16_Averaged_df = average_intensity(df = SAMPLE16_Normalized_df , intensity_name= 'sample16')\n",
    "SAMPLE17_Averaged_df = average_intensity(df = SAMPLE17_Normalized_df , intensity_name= 'sample17')\n",
    "\n",
    "print(SAMPLE1_Averaged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ed1081-cda5-40d1-a13c-6cf13e8893f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of DataFrame names\n",
    "data_frames = [SAMPLE1_Averaged_df, SAMPLE2_Averaged_df, SAMPLE3_Averaged_df, \n",
    "               SAMPLE4_Averaged_df, SAMPLE5_Averaged_df, SAMPLE6_Averaged_df, \n",
    "               SAMPLE7_Averaged_df, SAMPLE8_Averaged_df ,SAMPLE9_Averaged_df,\n",
    "               SAMPLE10_Averaged_df,SAMPLE11_Averaged_df,SAMPLE12_Averaged_df,\n",
    "               SAMPLE13_Averaged_df,SAMPLE14_Averaged_df,SAMPLE15_Averaged_df,\n",
    "               SAMPLE16_Averaged_df,SAMPLE17_Averaged_df]\n",
    "\n",
    "# Initialize the new DataFrame with the 'wavelength' column from the first DataFrame\n",
    "new_df = data_frames[0][['wavelength']].copy()\n",
    "\n",
    "# Add 'sample' columns from each DataFrame\n",
    "for i, df in enumerate(data_frames):\n",
    "    sample_column = f'sample{i+1}'\n",
    "    new_df[sample_column] = df[sample_column]\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6237048d-c372-415a-9746-454dc1c7cb69",
   "metadata": {},
   "source": [
    "# SELECTION OF PEAKS , TO DETERMINE THE PEAK START AND STOP "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe90b35-be37-4b81-84ed-a7a01ee0ff3e",
   "metadata": {},
   "source": [
    "# Wavelengths for Detected Peak(red circles above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232d93d7-0216-48ab-a9f1-65bd86e72fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample_Spectra_List = []\n",
    "\n",
    "for iteam in Selected_Sample_Spectra.wavelength:\n",
    "    iteam = float(iteam)\n",
    "    Sample_Spectra_List.append(iteam)\n",
    "    \n",
    "print(Sample_Spectra_List)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d264b105-c4c7-4506-9fa5-2f2a1a1ba38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Selected_Sample_Spectra_min_list = []\n",
    "\n",
    "Selected_Sample_Spectra_left = SAMPLE1_Averaged_df.iloc[info['left_ips']] \n",
    "Selected_Sample_Spectra_min_list = (Selected_Sample_Spectra_left['wavelength']).tolist()\n",
    "\n",
    "print (Selected_Sample_Spectra_min_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff59b6ca-2f7b-4869-a685-3fccac13d04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Selected_Sample_Spectra_max_list = []\n",
    "\n",
    "\n",
    "Selected_Sample_Spectra_right = SAMPLE1_Averaged_df.iloc[info['right_ips']] \n",
    "Selected_Sample_Spectra_max_list = (Selected_Sample_Spectra_right['wavelength']).tolist()\n",
    "\n",
    "print (Selected_Sample_Spectra_max_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3fcb6c-6a2a-40b3-acad-67b6b987a1c9",
   "metadata": {},
   "source": [
    "# COMBINED LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b888b411-bc37-4922-b7f8-900e4fc08ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength_min_max_list = [[a, b] for a, b in zip(Selected_Sample_Spectra_min_list, Selected_Sample_Spectra_max_list)]\n",
    "\n",
    "print(wavelength_min_max_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a345c8-4bba-45cd-895f-6b367d9177f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a list to store the maximum peaks for each wavelength range\n",
    "max_peaks_all_ranges = []\n",
    "\n",
    "# Loop through each wavelength range\n",
    "for wavelength_min, wavelength_max in wavelength_min_max_list:\n",
    "    # Filter the DataFrame for the current wavelength range\n",
    "    filtered_df = new_df[(new_df[\"wavelength\"] >= wavelength_min) & (new_df[\"wavelength\"] <= wavelength_max)]\n",
    "    #print(filtered_df)\n",
    "    \n",
    "    \n",
    "    # Find the maximum value for each sample column within the filtered DataFrame\n",
    "    max_peaks = []\n",
    "    for sample in filtered_df.columns[1:]:  # Skip the 'wavelength' column\n",
    "        max_value = filtered_df[sample].max()\n",
    "        min_value = filtered_df[sample].min()\n",
    "        max_peaks.append(max_value)\n",
    "    \n",
    "    # Append the list of maximum peaks for this range to the main list\n",
    "    max_peaks_all_ranges.append(max_peaks)\n",
    "\n",
    "\n",
    "# Print the results\n",
    "#for i, max_peaks in enumerate(max_peaks_all_ranges, start=1):\n",
    "    #print(f\"Range {i} max peaks: {max_peaks}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bf4be2-465a-4c63-bbf3-e75b0224fa58",
   "metadata": {},
   "source": [
    "# LIST FOR NIST ELEMENT PEAKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a98298b-4a4b-4349-af9d-f963d0dc7cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ele = 'Mo'\n",
    "# NISTDB_Reference_Spectra = pd.read_csv(r\"NIST_3/\" + ele +\".csv\" , encoding = 'windows - 1252' , usecols=(3,4,5,6,7,8))\n",
    "# Reference_Spectra_List = (NISTDB_Reference_Spectra['obs_wl_air(nm)']).tolist()\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "New_Reference_Spectra = pd.read_csv(r\"NIST_2/\" + ele +\".csv\" , encoding = 'windows - 1252' , usecols=(0,1))\n",
    "\n",
    "\n",
    "Reference_Spectra_List = (New_Reference_Spectra['Wavelength'] / 10).tolist()\n",
    "print(Reference_Spectra_List)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403e88f3-0448-4f2e-bb58-cae739a76001",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reference_Spectra_Min_Max = []\n",
    "Reference_Spectra_Min_Max = [[num - 0.025, num + 0.025] for num in Reference_Spectra_List]     \n",
    "    \n",
    "print(Reference_Spectra_Min_Max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57b4b56-ebfe-4842-ba53-8fa6f27a964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "# Provided data (as an example, add more sublists as needed)\n",
    "data = max_peaks_all_ranges\n",
    "\n",
    "elements = {\n",
    "    'Element': ['C'  , 'Mn', 'Si', 'Al', 'Cr', 'Cu', 'N', 'Ni' , 'Nb' ,'Mo', 'Ti'],\n",
    "    'SAMPLE1': [0.15 , 1.9, 0.3, 0.04, 0.41, 0.02, 0.004, 0.030, 0.006, 0.101, 0.044],\n",
    "    'SAMPLE2': [0.15 , 1.8, 0.3, 0.04, 0.42, 0.02, 0.004, 0.037, 0.006, 0.105, 0.037],\n",
    "    'SAMPLE3': [0.16 , 2.3, 0.5, 0.69, 0.70, 0.03, 0.003, 0.048, 0.032, 0.023, 0.025],\n",
    "    'SAMPLE4': [0.23 , 1.2, 0.2, 0.03, 0.14, 0.02, 0.004, 0.020, 0.001, 0.000, 0.034],\n",
    "    'SAMPLE5': [0.21 , 1.9, 1.8, 0.04, 0.05, 0.03, 0.003, 0.037, 0.056, 0.006, 0.014],\n",
    "    'SAMPLE6': [0.07 , 2.3, 0.2, 0.04, 0.60, 0.02, 0.005, 0.040, 0.001, 0.020, 0.051],\n",
    "    'SAMPLE7': [0.003, 0.1, 0.0, 0.02, 0.03, 0.01, 0.002, 0.020, 0.001, 0.005, 0.068],\n",
    "    'SAMPLE8': [0.06 , 1.1, 0.4, 0.04, 0.03, 0.01, 0.004, 0.010, 0.046, 0.002, 0.028],\n",
    "}\n",
    "\n",
    "# Extract 'Mn' values for samples 1 to 8\n",
    "mn_values = [elements[f'SAMPLE{i}'][9] for i in range(1, 9)]\n",
    "\n",
    "results = []\n",
    "\n",
    "# Loop through each sublist in data and perform linear regression\n",
    "for idx, sublist in enumerate(data):\n",
    "    X = np.array(sublist[:8]).reshape(-1, 1)  # Take only the first 8 values corresponding to samples 1 to 8\n",
    "    y = np.array(mn_values)\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Predict the values\n",
    "    #y_pred = model.predict(X)\n",
    "    \n",
    "    # Calculate R² and RMSE\n",
    "    r2 = model.score(X,y)\n",
    "    # Calculate Root Mean Squared Error (RMSE)\n",
    "    rmse = np.sqrt(mean_squared_error(X,y))\n",
    "    slope = model.coef_\n",
    "    intercept = model.intercept_\n",
    "\n",
    "    for cell in Reference_Spectra_Min_Max: \n",
    "        if Sample_Spectra_List[idx] >= cell[0] and Sample_Spectra_List[idx] <= cell[1]:\n",
    "            results.append({'wavelength': Sample_Spectra_List[idx], 'wavelength_min': Selected_Sample_Spectra_min_list[idx] , 'wavelength_max': Selected_Sample_Spectra_max_list[idx], 'R2': r2, 'RMSE': rmse ,'slope': slope , 'intercept': intercept , 'Index' : idx } )\n",
    "\n",
    "# # Sort the results by R² in descending order\n",
    "# sorted_results = sorted(results, key=lambda x: x['R2'], reverse=True)\n",
    "\n",
    "# Filter the results where slope is positive\n",
    "filtered_results = [result for result in results if result['slope'] > 0]\n",
    "\n",
    "# Sort the filtered results by R² in descending order\n",
    "sorted_filtered_results = sorted(filtered_results, key=lambda x: x['R2'], reverse=True)\n",
    "\n",
    "# Display the results\n",
    "df = pd.DataFrame(sorted_filtered_results[:50])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2f72de-a601-4b33-82bb-c090bc077d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "# Provided data (as an example, add more sublists as needed)\n",
    "data_1 = max_peaks_all_ranges\n",
    "\n",
    "\n",
    "elements_1 = {\n",
    "    'Element':  [   'C', 'Si',  'Mn',    'P',    'S',  'Cr',  'Mo',  'Ni',  'Al',  'Co',  'Cu',   'Nb',   'Ti',    'V',   'Sn',   'W',   'Zr',   'Pb',    'B'],\n",
    "    'SAMPLE9':  [0.1222, 0.13, 0.571, 0.0257, 0.0075, 0.550, 0.000, 0.000, 0.280, 0.000, 0.036, 0.0191, 0.0353, 0.0071, 0.0000, 0.000, 0.0065, 0.0000, 0.0016],\n",
    "    'SAMPLE10': [0.0847, 0.10, 0.489, 0.0156, 0.0140, 0.020, 0.007, 0.000, 0.413, 0.000, 0.101, 0.0000, 0.0086, 0.0038, 0.0000, 0.016, 0.0069, 0.0000, 0.0015],\n",
    "    'SAMPLE11': [0.2990, 0.32, 0.622, 0.0205, 0.0079, 2.150, 0.126, 0.000, 3.430, 0.000, 0.049, 0.0337, 0.0502, 0.0246, 0.0000, 0.000, 0.0078, 0.0000, 0.0027],\n",
    "    'SAMPLE12': [0.0032, 0.00, 0.000, 0.0049, 0.0058, 0.000, 0.007, 0.000, 0.000, 0.000, 0.006, 0.0000, 0.0000, 0.0000, 0.000, 0.021, 0.0055, 0.0000, 0.0000],\n",
    "    'SAMPLE13': [0.2734, 0.09, 0.347, 0.0225, 0.0147, 0.021, 0.008, 0.047, 0.000, 0.000, 0.044, 0.0021, 0.0000, 0.0029, 0.0000, 0.000, 0.0071, 0.0000, 0.0009],\n",
    "    'SAMPLE14': [0.8027, 0.67, 0.428, 0.0402, 0.0240, 0.591, 0.010, 0.054, 0.775, 0.000, 0.220, 0.0169, 0.0181, 0.0087, 0.0000, 0.000, 0.0091, 0.0000, 0.0019],\n",
    "    'SAMPLE15': [0.6353, 0.58, 0.473, 0.0415, 0.0238, 0.184, 0.005, 0.075, 1.995, 0.000, 0.430, 0.0136, 0.0158, 0.0061, 0.0120, 0.000, 0.0121, 0.0000, 0.0023],\n",
    "    'SAMPLE16': [0.6632, 0.33, 0.515, 0.0323, 0.0176, 0.194, 0.021, 0.077, 0.029, 0.000, 1.585, 0.0000, 0.0067, 0.0000, 0.0150, 0.000, 0.0000, 0.0000, 0.0018],\n",
    "    'SAMPLE17': [0.0943, 0.00, 0.208, 0.0250, 0.0130, 0.007, 0.007, 0.023, 0.000, 0.000, 0.067, 0.0030, 0.0000, 0.0023, 0.0000, 0.000, 0.0071, 0.0000, 0.0005],\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Extract 'Mn' values for samples 9 to 18\n",
    "mn_values_1 = [elements_1[f'SAMPLE{i}'][6] for i in range(9, 18)]\n",
    "\n",
    "results_1 = []\n",
    "\n",
    "# Loop through each sublist in data and perform linear regression\n",
    "for idx_1, sublist in enumerate(data_1):\n",
    "    X_1 = np.array(sublist[8:]).reshape(-1, 1)  # Take only the values corresponding to samples 9 to 17\n",
    "    y_1 = np.array(mn_values_1)\n",
    "    \n",
    "    # Create and train the model\n",
    "    model_1 = LinearRegression()\n",
    "    model_1.fit(X_1, y_1)\n",
    "    \n",
    "    # Predict the values\n",
    "    #y_pred = model.predict(X)\n",
    "    \n",
    "   # Calculate R² and RMSE\n",
    "    r2_1 = model_1.score(X_1,y_1)\n",
    "    # Calculate Root Mean Squared Error (RMSE)\n",
    "    rmse_1 = np.sqrt(mean_squared_error(X_1,y_1))\n",
    "    slope_1 = model_1.coef_\n",
    "    intercept_1 = model_1.intercept_\n",
    "    for cell_1 in Reference_Spectra_Min_Max: \n",
    "        if Sample_Spectra_List[idx_1] >= cell_1[0] and Sample_Spectra_List[idx_1] <= cell_1[1]:\n",
    "                results_1.append({'wavelength': Sample_Spectra_List[idx_1],'wavelength_min': Selected_Sample_Spectra_min_list[idx_1] , 'wavelength_max': Selected_Sample_Spectra_max_list[idx_1], 'R2': r2_1, 'RMSE': rmse_1 , 'slope': slope_1 , 'intercept': intercept_1, 'Index' : idx_1 } )\n",
    "\n",
    "\n",
    "# Filter the results where slope is positive\n",
    "filtered_results_1 = [result for result in results_1 if result['slope'] > 0]\n",
    "\n",
    "# Sort the filtered results by R² in descending order\n",
    "sorted_filtered_results_1 = sorted(filtered_results_1, key=lambda x: x['R2'], reverse=True)\n",
    "\n",
    "# Display the top 50 results\n",
    "df_1 = pd.DataFrame(sorted_filtered_results_1[:50])\n",
    "print(df_1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
