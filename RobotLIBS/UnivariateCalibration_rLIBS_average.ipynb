{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4392714e-2e7c-4828-91aa-b8f81294591f",
   "metadata": {},
   "source": [
    "# IMPORTING THE LIBRARIES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d525889-7089-450b-8158-612b0ddafbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb12269-8ea9-48b9-bb59-b6a6fe3825b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.pyplot as plt1 \n",
    "import peaky\n",
    "\n",
    "import statistics\n",
    "import os\n",
    "\n",
    "###############################################\n",
    "from peakutils import indexes\n",
    "from peakutils import baseline\n",
    "from scipy.signal import find_peaks as fp\n",
    "from scipy.signal import savgol_filter \n",
    "\n",
    "###############################################\n",
    "from bokeh.plotting import figure , show\n",
    "from pybaselines import whittaker as pl\n",
    "from lmfit.models import VoigtModel\n",
    "\n",
    "\n",
    "\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdb69c6-3ad7-4ef0-9464-62b03f62397c",
   "metadata": {},
   "source": [
    "# DATA ARRANGEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b58fa81-9ce3-4234-8b5a-b858bddc483d",
   "metadata": {},
   "source": [
    "In the main directory we can see that there are 8 subfolders. \n",
    "\n",
    "Each subfolder have almost 12 spectras per sample , the idea behind that would be , instead of having just one spectra per sample , and to just rely on one information , its always better have to multiple measurements per samples , and then this could be used for building the Calibration Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b23c0c-b3ac-4b59-924f-ef0d38a007a7",
   "metadata": {},
   "source": [
    "Instead of having 12 different csv per samples , its always good to have a single dataframe -> This new dataframe will have 1st column as wavelength , and 2nd -13th column as Intensities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0ecf88-6675-4703-b9b8-9f0d6835f6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder_path):\n",
    "    # List to store DataFrames for intensity columns\n",
    "    intensity_dfs = []\n",
    "\n",
    "    # List to store file names\n",
    "    file_names = []\n",
    "\n",
    "    # Get a list of .txt files in the folder\n",
    "    txt_files = [file_name for file_name in os.listdir(folder_path) if file_name.endswith('.txt')]\n",
    "\n",
    "    # Sort the .txt files based on their numerical order\n",
    "    # txt_files.sort(key=lambda x: int(re.search(r'_(\\d+)\\.txt', x).group(1)))\n",
    "\n",
    "    # Read the wavelength values from the first file\n",
    "    first_file_path = os.path.join(folder_path, txt_files[0])\n",
    "    wavelength_df = pd.read_csv(first_file_path, header=None, delimiter=';', usecols=[0], names=['wavelength'])\n",
    "\n",
    "    # Loop through each file in ascending order\n",
    "    for file_name in txt_files:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Read intensity values from each file into a DataFrame\n",
    "        intensity_df = pd.read_csv(file_path, header=None, delimiter=';', usecols=[1], names=['intensity'])\n",
    "        \n",
    "        # Store intensity DataFrame\n",
    "        intensity_dfs.append(intensity_df)\n",
    "        \n",
    "        # Store file name\n",
    "        file_names.append(os.path.splitext(file_name)[0])\n",
    "\n",
    "    # Concatenate intensity DataFrames\n",
    "    result_df = pd.concat(intensity_dfs, axis=1)\n",
    "\n",
    "    # Add the wavelength column to the result DataFrame\n",
    "    result_df = pd.concat([wavelength_df, result_df], axis=1)\n",
    "\n",
    "    # Rename the columns with file names\n",
    "    result_df.columns = ['wavelength'] + file_names\n",
    "\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5450aa4-3a59-4ff6-b34c-2fb3d96ca65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_intensity(df, intensity_name):\n",
    "    # Select intensity columns (from column 2 to column 13)\n",
    "    intensity_columns = df.columns[1:]\n",
    "\n",
    "    # Calculate the mean of intensity columns\n",
    "    averaged_intensity = df[intensity_columns].mean(axis=1)\n",
    "\n",
    "    # Create a new DataFrame with wavelength and averaged intensity\n",
    "    averaged_df = pd.DataFrame({'wavelength': df['wavelength'], intensity_name: averaged_intensity})\n",
    "\n",
    "    return averaged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7b2157-acda-46f4-9d9a-226024715bc2",
   "metadata": {},
   "source": [
    "Loading the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a46d114-05e7-46d0-93ef-59e912c20da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE1_Raw_df = load_data('Batch_2/sample_1')\n",
    "###################################################\n",
    "SAMPLE2_Raw_df = load_data('Batch_2/sample_2')\n",
    "###################################################\n",
    "SAMPLE3_Raw_df = load_data('Batch_2/sample_3')\n",
    "###################################################\n",
    "SAMPLE4_Raw_df = load_data('Batch_2/sample_4')\n",
    "###################################################\n",
    "SAMPLE5_Raw_df = load_data('Batch_2/sample_5')\n",
    "###################################################\n",
    "SAMPLE6_Raw_df = load_data('Batch_2/sample_6')\n",
    "###################################################\n",
    "SAMPLE7_Raw_df = load_data('Batch_2/sample_7')\n",
    "####################################################\n",
    "SAMPLE8_Raw_df = load_data('Batch_2/sample_8')\n",
    "####################################################\n",
    "SAMPLE9_Raw_df = load_data('Batch_3/sample_9')\n",
    "####################################################\n",
    "SAMPLE10_Raw_df = load_data('Batch_3/sample_10')\n",
    "####################################################\n",
    "SAMPLE11_Raw_df = load_data('Batch_3/sample_11')\n",
    "####################################################\n",
    "SAMPLE12_Raw_df = load_data('Batch_3/sample_12')\n",
    "####################################################\n",
    "SAMPLE13_Raw_df = load_data('Batch_3/sample_13')\n",
    "####################################################\n",
    "SAMPLE14_Raw_df = load_data('Batch_3/sample_14')\n",
    "####################################################\n",
    "SAMPLE15_Raw_df = load_data('Batch_3/sample_15')\n",
    "####################################################\n",
    "SAMPLE16_Raw_df = load_data('Batch_3/sample_16')\n",
    "####################################################\n",
    "SAMPLE17_Raw_df = load_data('Batch_3/sample_17')\n",
    "####################################################\n",
    "\n",
    "SAMPLE1_Raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a420d66a-2223-404e-be46-96a4d4d93c40",
   "metadata": {},
   "source": [
    "# Peak Selection and Data Trimming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90a6244-3918-411b-ab77-652212e87e72",
   "metadata": {},
   "source": [
    "The dataframe  which we have is very big ,it could be trimmed now according to the wavelength , by adjusting two parameters \"Wavelength_Min\" , \"Wavelength_Max\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fbcf80-80b5-4f24-b0d3-2dc01cfbed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# peak = 500.606\n",
    "# peak_min = (peak - 5) \n",
    "# peak_max = (peak + 5) \n",
    "\n",
    "#Getting the full wavelength\n",
    "Wavelength_Min = 230 #200.041162 #230\n",
    "Wavelength_Max = 540 #963.333130 #540\n",
    "\n",
    "\n",
    "SAMPLE1_Select_df = SAMPLE1_Raw_df[(SAMPLE1_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE1_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE2_Select_df = SAMPLE2_Raw_df[(SAMPLE2_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE2_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE3_Select_df = SAMPLE3_Raw_df[(SAMPLE3_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE3_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE4_Select_df = SAMPLE4_Raw_df[(SAMPLE4_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE4_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE5_Select_df = SAMPLE5_Raw_df[(SAMPLE5_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE5_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE6_Select_df = SAMPLE6_Raw_df[(SAMPLE6_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE6_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE7_Select_df = SAMPLE7_Raw_df[(SAMPLE7_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE7_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE8_Select_df = SAMPLE8_Raw_df[(SAMPLE8_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE8_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE9_Select_df = SAMPLE9_Raw_df[(SAMPLE9_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE9_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE10_Select_df = SAMPLE10_Raw_df[(SAMPLE10_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE10_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE11_Select_df = SAMPLE11_Raw_df[(SAMPLE11_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE11_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE12_Select_df = SAMPLE12_Raw_df[(SAMPLE12_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE12_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE13_Select_df = SAMPLE13_Raw_df[(SAMPLE13_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE13_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE14_Select_df = SAMPLE14_Raw_df[(SAMPLE14_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE14_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE15_Select_df = SAMPLE15_Raw_df[(SAMPLE15_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE15_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE16_Select_df = SAMPLE16_Raw_df[(SAMPLE16_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE16_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "SAMPLE17_Select_df = SAMPLE17_Raw_df[(SAMPLE17_Raw_df['wavelength'] >= Wavelength_Min) & (SAMPLE17_Raw_df['wavelength'] <= Wavelength_Max)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "SAMPLE1_Select_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0c9fff-fb15-4539-9330-9ed39eecf07a",
   "metadata": {},
   "source": [
    "Lets plot a line plot ,to get a better picture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2063c4-4f62-4727-aae2-333fb4e7d4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Selected_df_Plot = figure(title = 'Selected Data Plot' , x_axis_label = 'Wavelength' , y_axis_label = 'Intensity')\n",
    "\n",
    "Selected_df_Plot.line(SAMPLE1_Select_df.wavelength,SAMPLE1_Select_df.sample1_6 , line_width = 2, color =\"blue\" )\n",
    "# #####################################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE2_Select_df.wavelength,SAMPLE2_Select_df.sample2_6 , line_width = 2, color =\"orange\" )\n",
    "# ###############################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE3_Select_df.wavelength,SAMPLE3_Select_df.sample3_6 , line_width = 2, color =\"green\")\n",
    "######################################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE4_Select_df.wavelength,SAMPLE4_Select_df.sample4_6 , line_width = 2, color =\"red\")\n",
    "##############################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE5_Select_df.wavelength,SAMPLE5_Select_df.sample5_6 , line_width = 2, color =\"purple\")\n",
    "###############################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE6_Select_df.wavelength,SAMPLE6_Select_df.sample6_6 , line_width = 2, color =\"brown\")\n",
    "####################################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE7_Select_df.wavelength,SAMPLE7_Select_df.sample7_6 , line_width = 2, color =\"pink\")\n",
    "#################################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE8_Select_df.wavelength,SAMPLE8_Select_df.sample8_6 , line_width = 2, color =\"gray\")\n",
    "# ###################################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE9_Select_df.wavelength,SAMPLE9_Select_df.sample9_6 , line_width = 2, color =\"olive\")\n",
    "# ###################################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE10_Select_df.wavelength,SAMPLE10_Select_df.sample10_6 , line_width = 2, color =\"Cyan\")\n",
    "###################################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE11_Select_df.wavelength,SAMPLE11_Select_df.sample11_6 , line_width = 2, color =\"black\")\n",
    "###################################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE12_Select_df.wavelength,SAMPLE12_Select_df.sample12_6 , line_width = 2, color =\"tomato\")\n",
    "###################################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE13_Select_df.wavelength,SAMPLE13_Select_df.sample13_6 , line_width = 2, color =\"steelblue\")\n",
    "###################################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE14_Select_df.wavelength,SAMPLE14_Select_df.sample14_6 , line_width = 2, color =\"limegreen\")\n",
    "###################################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE15_Select_df.wavelength,SAMPLE15_Select_df.sample15_6 , line_width = 2, color =\"deeppink\")\n",
    "###################################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE16_Select_df.wavelength,SAMPLE16_Select_df.sample16_6 , line_width = 2, color =\"gold\")\n",
    "###################################################################################################################\n",
    "Selected_df_Plot.line(SAMPLE17_Select_df.wavelength,SAMPLE17_Select_df.sample17_6 , line_width = 2, color =\"indigo\")\n",
    "# ###################################################################################################################\n",
    "\n",
    "Selected_df_Plot.width = 900\n",
    "Selected_df_Plot.height = 500\n",
    "show(Selected_df_Plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32553d02-101b-463e-91a9-0bec5f82ba88",
   "metadata": {},
   "source": [
    "# Data Preprocessing of the Spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac0636c-323a-47ae-9af1-1f1c6443ac04",
   "metadata": {},
   "source": [
    "The above plot eventhough a spectra , is still a Raw Spectra , which still has lot of Artifects , before proceeding for the Univariate Calibration , its important to Pre Process the Raw Spectra accordingly. Various Pre Processing Techniques could be used here :- \n",
    "\n",
    "1) Baseline Correction - Very Very little  background radiation is still present in the spectra, which corresponds to the spectral baseline and imposes difficulties for quantitative elemental analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105566ee-f241-48a2-8c71-10d3c13bc5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_correction(df):\n",
    "    \"\"\"\n",
    "    Perform baseline correction on the intensity columns of the input DataFrame and create a new DataFrame with corrected values.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): Input DataFrame containing the wavelength and intensity columns.\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: New DataFrame with baseline-corrected intensity columns and the same wavelength column as the input DataFrame.\n",
    "    \"\"\"\n",
    "    # Copy the 'wavelength' column from the input DataFrame\n",
    "    new_df = pd.DataFrame({'wavelength': df['wavelength']})\n",
    "    \n",
    "    # Perform baseline correction for each intensity column and add them to the new DataFrame\n",
    "    for col in df.columns[1:]:  # Exclude the 'wavelength' column\n",
    "        baseline, _ = pl.asls(df[col])\n",
    "        corrected_values = df[col] - baseline\n",
    "        new_df[col] = corrected_values\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdddbd95-1f4e-4c7e-8d6e-6a5cc4f0a404",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE1_BaselineCorrected_df = baseline_correction(SAMPLE1_Select_df)\n",
    "SAMPLE2_BaselineCorrected_df = baseline_correction(SAMPLE2_Select_df)\n",
    "SAMPLE3_BaselineCorrected_df = baseline_correction(SAMPLE3_Select_df)\n",
    "SAMPLE4_BaselineCorrected_df = baseline_correction(SAMPLE4_Select_df)\n",
    "SAMPLE5_BaselineCorrected_df = baseline_correction(SAMPLE5_Select_df)\n",
    "SAMPLE6_BaselineCorrected_df = baseline_correction(SAMPLE6_Select_df)\n",
    "SAMPLE7_BaselineCorrected_df = baseline_correction(SAMPLE7_Select_df)\n",
    "SAMPLE8_BaselineCorrected_df = baseline_correction(SAMPLE8_Select_df)\n",
    "SAMPLE9_BaselineCorrected_df = baseline_correction(SAMPLE9_Select_df)\n",
    "SAMPLE10_BaselineCorrected_df = baseline_correction(SAMPLE10_Select_df)\n",
    "SAMPLE11_BaselineCorrected_df = baseline_correction(SAMPLE11_Select_df)\n",
    "SAMPLE12_BaselineCorrected_df = baseline_correction(SAMPLE12_Select_df)\n",
    "SAMPLE13_BaselineCorrected_df = baseline_correction(SAMPLE13_Select_df)\n",
    "SAMPLE14_BaselineCorrected_df = baseline_correction(SAMPLE14_Select_df)\n",
    "SAMPLE15_BaselineCorrected_df = baseline_correction(SAMPLE15_Select_df)\n",
    "SAMPLE16_BaselineCorrected_df = baseline_correction(SAMPLE16_Select_df)\n",
    "SAMPLE17_BaselineCorrected_df = baseline_correction(SAMPLE17_Select_df)\n",
    "\n",
    "SAMPLE1_BaselineCorrected_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9db0b74-0f88-4f7a-9f18-589f7faee8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE1_BaselineCorrected_all_df = baseline_correction(SAMPLE1_Raw_df)\n",
    "SAMPLE2_BaselineCorrected_all_df = baseline_correction(SAMPLE2_Raw_df)\n",
    "SAMPLE3_BaselineCorrected_all_df = baseline_correction(SAMPLE3_Raw_df)\n",
    "SAMPLE4_BaselineCorrected_all_df = baseline_correction(SAMPLE4_Raw_df)\n",
    "SAMPLE5_BaselineCorrected_all_df = baseline_correction(SAMPLE5_Raw_df)\n",
    "SAMPLE6_BaselineCorrected_all_df = baseline_correction(SAMPLE6_Raw_df)\n",
    "SAMPLE7_BaselineCorrected_all_df = baseline_correction(SAMPLE7_Raw_df)\n",
    "SAMPLE8_BaselineCorrected_all_df = baseline_correction(SAMPLE8_Raw_df)\n",
    "SAMPLE9_BaselineCorrected_all_df = baseline_correction(SAMPLE9_Raw_df)\n",
    "SAMPLE10_BaselineCorrected_all_df = baseline_correction(SAMPLE10_Raw_df)\n",
    "SAMPLE11_BaselineCorrected_all_df = baseline_correction(SAMPLE11_Raw_df)\n",
    "SAMPLE12_BaselineCorrected_all_df = baseline_correction(SAMPLE12_Raw_df)\n",
    "SAMPLE13_BaselineCorrected_all_df = baseline_correction(SAMPLE13_Raw_df)\n",
    "SAMPLE14_BaselineCorrected_all_df = baseline_correction(SAMPLE14_Raw_df)\n",
    "SAMPLE15_BaselineCorrected_all_df = baseline_correction(SAMPLE15_Raw_df)\n",
    "SAMPLE16_BaselineCorrected_all_df = baseline_correction(SAMPLE16_Raw_df)\n",
    "SAMPLE17_BaselineCorrected_all_df = baseline_correction(SAMPLE17_Raw_df)\n",
    "\n",
    "SAMPLE1_BaselineCorrected_all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3835fd-106c-49d1-aeb9-6308caa4b4e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Baseline_Correction_Plot = figure(title = 'Baseline Correction' , x_axis_label = 'Wavelength' , y_axis_label = 'Intensity')\n",
    "\n",
    "Baseline_Correction_Plot.line(SAMPLE9_Select_df.wavelength,SAMPLE9_Select_df.sample9_6 , line_width = 2, color =\"red\" )\n",
    "Baseline_Correction_Plot.line(SAMPLE9_BaselineCorrected_df.wavelength,SAMPLE9_BaselineCorrected_df.sample9_6 , line_width = 2, color =\"green\" )\n",
    "\n",
    "\n",
    "Baseline_Correction_Plot.width = 900\n",
    "Baseline_Correction_Plot.height = 500\n",
    "show(Baseline_Correction_Plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c6e970-ceb2-4d8f-8783-76534447c1c2",
   "metadata": {},
   "source": [
    "2) Normalization - Its usually noticed that , for a measurement of a similar sample ,there is a lot of scattering in the intensities , this typical artifect is called scattering.\n",
    "\n",
    "For Instance , you could see the plot above , Though this are the plots from the same sample SAMPLE1 , measured on 12 different Areas , its quite visible , for some  spectras , the peak heights or Intensities are not same.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7458b579-db93-4227-9d22-9408fc61d680",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def standard_normal_variate_normalization(df):\n",
    "#     # Selecting only the intensity columns (assuming the first column is wavelength)\n",
    "#     intensities = df.iloc[:, 1:]\n",
    "\n",
    "#     # Calculating mean and standard deviation for each column\n",
    "#     means = intensities.mean(axis=0)\n",
    "#     stds = intensities.std(axis=0)\n",
    "\n",
    "#     # Applying standard normal variate normalization column-wise\n",
    "#     normalized_intensities = (intensities - means) / stds\n",
    "\n",
    "#     # Combining the wavelength column with normalized intensities\n",
    "#     normalized_df = pd.concat([df.iloc[:, 0], normalized_intensities], axis=1)\n",
    "\n",
    "#     # Calculating mean and standard deviation for each normalized column\n",
    "#     normalized_means = normalized_intensities.mean(axis=0)\n",
    "#     normalized_stds = normalized_intensities.std(axis=0)\n",
    "\n",
    "#     return normalized_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76672e62-1bd9-4bac-8295-1f9b407173d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_normal_variate_normalization(df):\n",
    "    # Select columns containing intensities\n",
    "    intensity_cols = df.columns[1:]  #  columns 2 to 13 are intensities and are stored in intensity_cols\n",
    "\n",
    "    # SVN normalization\n",
    "    for col in intensity_cols:\n",
    "        mean_intensity = df[col].mean()\n",
    "        std_intensity = df[col].std()\n",
    "        df[col] = (df[col] - mean_intensity) / std_intensity\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9fb344-d091-4440-95c5-ead2096b8f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def total_intensity_normalization(df):\n",
    "    # Selecting only the intensity columns (assuming the first column is wavelength)\n",
    "    intensities = df.iloc[:, 1:]  \n",
    "\n",
    "    # Initialize an empty DataFrame to store normalized intensities\n",
    "    normalized_intensities = pd.DataFrame()\n",
    "\n",
    "    # Iterate over each column (each spectrum)\n",
    "    for column in intensities.columns:\n",
    "        spectrum = intensities[column]\n",
    "        total_intensity = spectrum.sum()\n",
    "        \n",
    "        # Normalize the spectrum by dividing each intensity value by the total intensity\n",
    "        normalized_spectrum = spectrum / total_intensity\n",
    "        \n",
    "        # Append the normalized spectrum to the DataFrame of normalized intensities\n",
    "        normalized_intensities[column] = normalized_spectrum\n",
    "\n",
    "    # Combine the wavelength column with normalized intensities\n",
    "    normalized_df = pd.concat([df.iloc[:, 0], normalized_intensities], axis=1)\n",
    "\n",
    "    return normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90877d4e-067d-4365-8d0f-cdeb89658062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_norm_normalization(df):\n",
    "    # Selecting only the intensity columns (assuming the first column is wavelength)\n",
    "    intensities_1 = df.iloc[:, 1:]  \n",
    "    \n",
    "    # Initialize an empty DataFrame to store normalized intensities\n",
    "    normalized_intensities_1 = pd.DataFrame()\n",
    "\n",
    "    # Iterate over each column (each spectrum)\n",
    "    for column_1 in intensities_1.columns:\n",
    "        spectrum_1 = intensities_1[column_1]\n",
    "        \n",
    "        # Calculate the norm of the spectrum using a simple equation\n",
    "        spectrum_norm = np.sqrt(np.sum(spectrum_1 ** 2))\n",
    "        \n",
    "        # Normalize the spectrum by dividing each intensity value by its norm\n",
    "        normalized_spectrum_1 = spectrum_1 / spectrum_norm\n",
    "        \n",
    "        # Assign the normalized spectrum to the DataFrame of normalized intensities\n",
    "        normalized_intensities_1[column_1] = normalized_spectrum_1\n",
    "\n",
    "    # Combine the wavelength column with normalized intensities\n",
    "    normalized_df_1 = pd.concat([df.iloc[:, 0], normalized_intensities_1], axis=1)\n",
    "    \n",
    "    return normalized_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3b59ac-7bd1-4b8a-9860-2357749345b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_intensity_normalization(df):\n",
    "    # Selecting only the intensity columns (assuming the first column is wavelength)\n",
    "    intensities_2 = df.iloc[:, 1:]  \n",
    "\n",
    "    # Initialize an empty DataFrame to store normalized intensities\n",
    "    normalized_intensities_2 = pd.DataFrame()\n",
    "\n",
    "    # Iterate over each column (each spectrum)\n",
    "    for column_2 in intensities_2.columns:\n",
    "        spectrum_2 = intensities_2[column_2]\n",
    "        \n",
    "        # Find the maximum intensity value in the spectrum\n",
    "        max_intensity = spectrum_2.max()\n",
    "        \n",
    "        # Normalize the spectrum by dividing each intensity value by the maximum intensity\n",
    "        normalized_spectrum_2 = spectrum_2 / max_intensity\n",
    "        \n",
    "        # Assign the normalized spectrum to the DataFrame of normalized intensities\n",
    "        normalized_intensities_2[column_2] = normalized_spectrum_2\n",
    "\n",
    "    # Combine the wavelength column with normalized intensities\n",
    "    normalized_df_2 = pd.concat([df.iloc[:, 0], normalized_intensities_2], axis=1)\n",
    "\n",
    "    return normalized_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d286b96-1e69-44d8-8b3f-05a9e322d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE1_Normalized_df = total_intensity_normalization(SAMPLE1_BaselineCorrected_df)\n",
    "SAMPLE2_Normalized_df = total_intensity_normalization(SAMPLE2_BaselineCorrected_df)\n",
    "SAMPLE3_Normalized_df = total_intensity_normalization(SAMPLE3_BaselineCorrected_df)\n",
    "SAMPLE4_Normalized_df = total_intensity_normalization(SAMPLE4_BaselineCorrected_df)\n",
    "SAMPLE5_Normalized_df = total_intensity_normalization(SAMPLE5_BaselineCorrected_df)\n",
    "SAMPLE6_Normalized_df = total_intensity_normalization(SAMPLE6_BaselineCorrected_df)\n",
    "SAMPLE7_Normalized_df = total_intensity_normalization(SAMPLE7_BaselineCorrected_df)\n",
    "SAMPLE8_Normalized_df = total_intensity_normalization(SAMPLE8_BaselineCorrected_df)\n",
    "SAMPLE9_Normalized_df = total_intensity_normalization(SAMPLE9_BaselineCorrected_df)\n",
    "SAMPLE10_Normalized_df = total_intensity_normalization(SAMPLE10_BaselineCorrected_df)\n",
    "SAMPLE11_Normalized_df = total_intensity_normalization(SAMPLE11_BaselineCorrected_df)\n",
    "SAMPLE12_Normalized_df = total_intensity_normalization(SAMPLE12_BaselineCorrected_df)\n",
    "SAMPLE13_Normalized_df = total_intensity_normalization(SAMPLE13_BaselineCorrected_df)\n",
    "SAMPLE14_Normalized_df = total_intensity_normalization(SAMPLE14_BaselineCorrected_df)\n",
    "SAMPLE15_Normalized_df = total_intensity_normalization(SAMPLE15_BaselineCorrected_df)\n",
    "SAMPLE16_Normalized_df = total_intensity_normalization(SAMPLE16_BaselineCorrected_df)\n",
    "SAMPLE17_Normalized_df = total_intensity_normalization(SAMPLE17_BaselineCorrected_df)\n",
    "\n",
    "SAMPLE1_Normalized_df\n",
    "\n",
    "Normalized_Plot = figure(title = 'After Normalization' , x_axis_label = 'Wavelength' , y_axis_label = 'Intensity')\n",
    "\n",
    "Normalized_Plot.line(SAMPLE1_Normalized_df.wavelength,SAMPLE1_Normalized_df.sample1_1 , line_width =2 , color = \"red\")\n",
    "Normalized_Plot.line(SAMPLE1_Normalized_df.wavelength,SAMPLE1_Normalized_df.sample1_2 , line_width =2 , color = \"green\")\n",
    "Normalized_Plot.line(SAMPLE1_Normalized_df.wavelength,SAMPLE1_Normalized_df.sample1_3 , line_width =2 , color = \"pink\")\n",
    "Normalized_Plot.line(SAMPLE1_Normalized_df.wavelength,SAMPLE1_Normalized_df.sample1_4 , line_width =2 , color = \"yellow\")\n",
    "Normalized_Plot.line(SAMPLE1_Normalized_df.wavelength,SAMPLE1_Normalized_df.sample1_5 , line_width =2 , color = \"blue\")\n",
    "Normalized_Plot.line(SAMPLE1_Normalized_df.wavelength,SAMPLE1_Normalized_df.sample1_6 , line_width =2 , color = \"orange\")\n",
    "Normalized_Plot.line(SAMPLE1_Normalized_df.wavelength,SAMPLE1_Normalized_df.sample1_7, line_width =2 , color = \"brown\")\n",
    "Normalized_Plot.line(SAMPLE1_Normalized_df.wavelength,SAMPLE1_Normalized_df.sample1_8 , line_width =2 , color = \"black\")\n",
    "Normalized_Plot.line(SAMPLE1_Normalized_df.wavelength,SAMPLE1_Normalized_df.sample1_9 , line_width =2 , color = \"tomato\")\n",
    "Normalized_Plot.line(SAMPLE1_Normalized_df.wavelength,SAMPLE1_Normalized_df.sample1_10 , line_width =2 , color = \"steelblue\")\n",
    "Normalized_Plot.line(SAMPLE1_Normalized_df.wavelength,SAMPLE1_Normalized_df.sample1_11, line_width =2 , color = \"gold\")\n",
    "Normalized_Plot.line(SAMPLE1_Normalized_df.wavelength,SAMPLE1_Normalized_df.sample1_12 , line_width =2 , color = \"indigo\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Normalized_Plot.width = 900\n",
    "Normalized_Plot.height = 500\n",
    "show(Normalized_Plot)\n",
    "\n",
    "\n",
    "\n",
    "# mean_intensity = SAMPLE1_Normalized_df['sample1_13'].mean()\n",
    "# std_intensity = SAMPLE1_Normalized_df['sample1_13'].std()\n",
    "\n",
    "# print(mean_intensity)\n",
    "# print(std_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30bc282-0474-4015-9f62-2a0944d84c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE1_Normalized_all_df = total_intensity_normalization(SAMPLE1_BaselineCorrected_all_df)\n",
    "SAMPLE2_Normalized_all_df = total_intensity_normalization(SAMPLE2_BaselineCorrected_all_df)\n",
    "SAMPLE3_Normalized_all_df = total_intensity_normalization(SAMPLE3_BaselineCorrected_all_df)\n",
    "SAMPLE4_Normalized_all_df = total_intensity_normalization(SAMPLE4_BaselineCorrected_all_df)\n",
    "SAMPLE5_Normalized_all_df = total_intensity_normalization(SAMPLE5_BaselineCorrected_all_df)\n",
    "SAMPLE6_Normalized_all_df = total_intensity_normalization(SAMPLE6_BaselineCorrected_all_df)\n",
    "SAMPLE7_Normalized_all_df = total_intensity_normalization(SAMPLE7_BaselineCorrected_all_df)\n",
    "SAMPLE8_Normalized_all_df = total_intensity_normalization(SAMPLE8_BaselineCorrected_all_df)\n",
    "SAMPLE9_Normalized_all_df = total_intensity_normalization(SAMPLE9_BaselineCorrected_all_df)\n",
    "SAMPLE10_Normalized_all_df = total_intensity_normalization(SAMPLE10_BaselineCorrected_all_df)\n",
    "SAMPLE11_Normalized_all_df = total_intensity_normalization(SAMPLE11_BaselineCorrected_all_df)\n",
    "SAMPLE12_Normalized_all_df = total_intensity_normalization(SAMPLE12_BaselineCorrected_all_df)\n",
    "SAMPLE13_Normalized_all_df = total_intensity_normalization(SAMPLE13_BaselineCorrected_all_df)\n",
    "SAMPLE14_Normalized_all_df = total_intensity_normalization(SAMPLE14_BaselineCorrected_all_df)\n",
    "SAMPLE15_Normalized_all_df = total_intensity_normalization(SAMPLE15_BaselineCorrected_all_df)\n",
    "SAMPLE16_Normalized_all_df = total_intensity_normalization(SAMPLE16_BaselineCorrected_all_df)\n",
    "SAMPLE17_Normalized_all_df = total_intensity_normalization(SAMPLE17_BaselineCorrected_all_df)\n",
    "\n",
    "print(SAMPLE1_Normalized_all_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e35b5ca-144e-4c3b-8737-93383ae71217",
   "metadata": {},
   "source": [
    "3) Smoothing of the Spectrum - Now even though , the signal from the hLIBS Instrument doesn't appear to have much noise , we could still implement this additional signal smoothing steps , in our Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c46c4fd-ab8f-4c7f-8017-d9cc346d819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_savitzky_golay_smoothing(df, window_length=20, polyorder=15):\n",
    "    # Selecting only the normalized intensity columns\n",
    "    normalized_intensities = df.iloc[:, 1:]\n",
    "\n",
    "    # Applying Savitzky-Golay smoothing to each intensity column\n",
    "    smoothed_intensities = normalized_intensities.apply(lambda x: savgol_filter(x, window_length, polyorder), axis=0)\n",
    "\n",
    "    # Combining wavelength column with smoothed intensities\n",
    "    smoothed_df = pd.concat([df.iloc[:, 0], smoothed_intensities], axis=1)\n",
    "\n",
    "    return smoothed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee32c802-e357-45f1-b847-e8260352c56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE1_Smoothed_df = SAMPLE1_Normalized_df\n",
    "SAMPLE2_Smoothed_df = SAMPLE2_Normalized_df\n",
    "SAMPLE3_Smoothed_df = SAMPLE3_Normalized_df\n",
    "SAMPLE4_Smoothed_df = SAMPLE4_Normalized_df\n",
    "SAMPLE5_Smoothed_df = SAMPLE5_Normalized_df\n",
    "SAMPLE6_Smoothed_df = SAMPLE6_Normalized_df\n",
    "SAMPLE7_Smoothed_df = SAMPLE7_Normalized_df\n",
    "SAMPLE8_Smoothed_df = SAMPLE8_Normalized_df\n",
    "SAMPLE9_Smoothed_df = SAMPLE9_Normalized_df\n",
    "SAMPLE10_Smoothed_df = SAMPLE10_Normalized_df\n",
    "SAMPLE11_Smoothed_df = SAMPLE11_Normalized_df\n",
    "SAMPLE12_Smoothed_df = SAMPLE12_Normalized_df\n",
    "SAMPLE13_Smoothed_df = SAMPLE13_Normalized_df\n",
    "SAMPLE14_Smoothed_df = SAMPLE14_Normalized_df\n",
    "SAMPLE15_Smoothed_df = SAMPLE15_Normalized_df\n",
    "SAMPLE16_Smoothed_df = SAMPLE16_Normalized_df\n",
    "SAMPLE17_Smoothed_df = SAMPLE17_Normalized_df\n",
    "\n",
    "\n",
    "Smoothed_Plot = figure(title = 'After Smoothing of the Spectrum' , x_axis_label = 'Wavelength' , y_axis_label = 'Intensity')\n",
    "\n",
    "Smoothed_Plot.line(SAMPLE1_Smoothed_df.wavelength,SAMPLE1_Smoothed_df.sample1_6 , line_width = 2, color =\"blue\" )\n",
    "#####################################################################################################################\n",
    "Smoothed_Plot.line(SAMPLE2_Smoothed_df.wavelength,SAMPLE2_Smoothed_df.sample2_6 , line_width = 2, color =\"orange\" )\n",
    "###############################################################################################################\n",
    "Smoothed_Plot.line(SAMPLE3_Smoothed_df.wavelength,SAMPLE3_Smoothed_df.sample3_6 , line_width = 2, color =\"green\")\n",
    "######################################################################################################################\n",
    "Smoothed_Plot.line(SAMPLE4_Smoothed_df.wavelength,SAMPLE4_Smoothed_df.sample4_6 , line_width = 2, color =\"red\")\n",
    "#############################################################################################################\n",
    "Smoothed_Plot.line(SAMPLE5_Smoothed_df.wavelength,SAMPLE5_Smoothed_df.sample5_6 , line_width = 2, color =\"purple\")\n",
    "###############################################################################################################\n",
    "Smoothed_Plot.line(SAMPLE6_Smoothed_df.wavelength,SAMPLE6_Smoothed_df.sample6_6 , line_width = 2, color =\"brown\")\n",
    "###################################################################################################################\n",
    "Smoothed_Plot.line(SAMPLE7_Smoothed_df.wavelength,SAMPLE7_Smoothed_df.sample7_6 , line_width = 2, color =\"pink\")\n",
    "##################################################################################################################\n",
    "Smoothed_Plot.line(SAMPLE8_Smoothed_df.wavelength,SAMPLE8_Smoothed_df.sample8_6 , line_width = 2, color =\"gray\")\n",
    "# ###################################################################################################################\n",
    "Smoothed_Plot.line(SAMPLE9_Smoothed_df.wavelength,SAMPLE9_Smoothed_df.sample9_6 , line_width = 2, color =\"olive\")\n",
    "###################################################################################################################\n",
    "Smoothed_Plot.line(SAMPLE10_Smoothed_df.wavelength,SAMPLE10_Smoothed_df.sample10_6 , line_width = 2, color =\"Cyan\")\n",
    "###################################################################################################################\n",
    "Smoothed_Plot.line(SAMPLE11_Smoothed_df.wavelength,SAMPLE11_Smoothed_df.sample11_6 , line_width = 2, color =\"black\")\n",
    "###################################################################################################################\n",
    "Smoothed_Plot.line(SAMPLE12_Smoothed_df.wavelength,SAMPLE12_Smoothed_df.sample12_6 , line_width = 2, color =\"tomato\")\n",
    "###################################################################################################################\n",
    "Smoothed_Plot.line(SAMPLE13_Smoothed_df.wavelength,SAMPLE13_Smoothed_df.sample13_6 , line_width = 2, color =\"steelblue\")\n",
    "###################################################################################################################\n",
    "Smoothed_Plot.line(SAMPLE14_Smoothed_df.wavelength,SAMPLE14_Smoothed_df.sample14_6 , line_width = 2, color =\"limegreen\")\n",
    "###################################################################################################################\n",
    "Smoothed_Plot.line(SAMPLE15_Smoothed_df.wavelength,SAMPLE15_Smoothed_df.sample15_6 , line_width = 2, color =\"deeppink\")\n",
    "###################################################################################################################\n",
    "Smoothed_Plot.line(SAMPLE16_Smoothed_df.wavelength,SAMPLE16_Smoothed_df.sample16_6 , line_width = 2, color =\"gold\")\n",
    "###################################################################################################################\n",
    "Smoothed_Plot.line(SAMPLE17_Smoothed_df.wavelength,SAMPLE17_Smoothed_df.sample17_6 , line_width = 2, color =\"indigo\")\n",
    "###################################################################################################################\n",
    "\n",
    "\n",
    "Smoothed_Plot.width = 900\n",
    "Smoothed_Plot.height = 500\n",
    "#show(Smoothed_Plot)\n",
    "\n",
    "SAMPLE1_Smoothed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bcd5f5-5600-4cab-aed6-36e146b935c6",
   "metadata": {},
   "source": [
    "4) Averaging the Spectrum - The final steps is to Average the specta files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3ac805-006d-40d8-aee0-1006284144a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Define the Gaussian profile\n",
    "def gaussian(x, center, amplitude, sigma):\n",
    "    return amplitude * np.exp(-((x - center)**2) / (2 * sigma**2))\n",
    "\n",
    "def fit_gaussian_profile(df):\n",
    "    # Extract the wavelength data\n",
    "    wavelength = df.iloc[:, 0].values\n",
    "\n",
    "    # Prepare to store the fitted profiles\n",
    "    fitted_data = pd.DataFrame({'wavelength': wavelength})\n",
    "\n",
    "    # Iterate over each intensity column\n",
    "    for column in df.columns[1:]:\n",
    "        intensity = df[column].values\n",
    "\n",
    "        # Find the peak\n",
    "        peak_indices, _ = find_peaks(intensity)\n",
    "        if len(peak_indices) == 0:\n",
    "            raise ValueError(f\"No peaks found in the data for column {column}.\")\n",
    "        \n",
    "        peak_index = peak_indices[np.argmax(intensity[peak_indices])]\n",
    "        center_guess = wavelength[peak_index]\n",
    "        amplitude_guess = intensity[peak_index]\n",
    "\n",
    "        # Find FWHM\n",
    "        half_max = amplitude_guess / 2\n",
    "        indices_above_half_max = np.where(intensity >= half_max)[0]\n",
    "\n",
    "        if len(indices_above_half_max) >= 2:\n",
    "            # Interpolate to find the exact FWHM\n",
    "            left_index = indices_above_half_max[0]\n",
    "            right_index = indices_above_half_max[-1]\n",
    "            fwhm = wavelength[right_index] - wavelength[left_index]\n",
    "\n",
    "            # Convert FWHM to sigma\n",
    "            sigma_guess = fwhm / (2 * np.sqrt(2 * np.log(2)))\n",
    "        else:\n",
    "            # Fallback to the range-based estimate if FWHM calculation fails\n",
    "            sigma_guess = (wavelength[-1] - wavelength[0]) / 10\n",
    "\n",
    "        # Initial guesses for the fit parameters\n",
    "        initial_guesses = [center_guess, amplitude_guess, sigma_guess]\n",
    "\n",
    "        # Fit the Gaussian profile to the data\n",
    "        popt, _ = curve_fit(gaussian, wavelength, intensity, p0=initial_guesses)\n",
    "\n",
    "        # Generate the fitted Gaussian profile using the best fit parameters\n",
    "        fitted_profile = gaussian(wavelength, *popt)\n",
    "\n",
    "        # Add the fitted profile to the DataFrame\n",
    "        fitted_data[column] = fitted_profile\n",
    "\n",
    "    return fitted_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6c2b3f-ed0b-4c9f-81ce-4447a5da7930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from scipy.optimize import curve_fit\n",
    "# from scipy.signal import find_peaks\n",
    "# from scipy.special import wofz\n",
    "\n",
    "# # Define the Voigt profile\n",
    "# def voigt(x, center, amplitude, sigma, gamma):\n",
    "#     z = ((x - center) + 1j * gamma) / (sigma * np.sqrt(2))\n",
    "#     return amplitude * np.real(wofz(z)) / (sigma * np.sqrt(2 * np.pi))\n",
    "\n",
    "# def fit_voigt_profile(df):\n",
    "#     # Extract the wavelength data\n",
    "#     wavelength = df.iloc[:, 0].values\n",
    "\n",
    "#     # Prepare to store the fitted profiles\n",
    "#     fitted_data = pd.DataFrame({'wavelength': wavelength})\n",
    "\n",
    "#     # Iterate over each intensity column\n",
    "#     for column in df.columns[1:]:\n",
    "#         intensity = df[column].values\n",
    "\n",
    "#         # Find the peak\n",
    "#         peak_indices, _ = find_peaks(intensity)\n",
    "#         if len(peak_indices) == 0:\n",
    "#             raise ValueError(f\"No peaks found in the data for column {column}.\")\n",
    "        \n",
    "#         peak_index = peak_indices[np.argmax(intensity[peak_indices])]\n",
    "#         center_guess = wavelength[peak_index]\n",
    "#         amplitude_guess = intensity[peak_index]\n",
    "\n",
    "#         # Find FWHM\n",
    "#         half_max = amplitude_guess / 2\n",
    "#         indices_above_half_max = np.where(intensity >= half_max)[0]\n",
    "\n",
    "#         if len(indices_above_half_max) >= 2:\n",
    "#             # Interpolate to find the exact FWHM\n",
    "#             left_index = indices_above_half_max[0]\n",
    "#             right_index = indices_above_half_max[-1]\n",
    "#             fwhm = wavelength[right_index] - wavelength[left_index]\n",
    "\n",
    "#             # Convert FWHM to sigma (for Gaussian part of Voigt)\n",
    "#             sigma_guess = fwhm / (2 * np.sqrt(2 * np.log(2)))\n",
    "#         else:\n",
    "#             # Fallback to the range-based estimate if FWHM calculation fails\n",
    "#             sigma_guess = (wavelength[-1] - wavelength[0]) / 10\n",
    "\n",
    "#         # Estimate for gamma (Lorentzian part of Voigt)\n",
    "#         gamma_guess = sigma_guess / 2\n",
    "\n",
    "#         # Initial guesses for the fit parameters\n",
    "#         initial_guesses = [center_guess, amplitude_guess, sigma_guess, gamma_guess]\n",
    "\n",
    "#         # Fit the Voigt profile to the data\n",
    "#         popt, _ = curve_fit(voigt, wavelength, intensity, p0=initial_guesses)\n",
    "\n",
    "#         # Generate the fitted Voigt profile using the best fit parameters\n",
    "#         fitted_profile = voigt(wavelength, *popt)\n",
    "\n",
    "#         # Add the fitted profile to the DataFrame\n",
    "#         fitted_data[column] = fitted_profile\n",
    "\n",
    "#     return fitted_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cf28fd-368f-4417-9010-977eb906ac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_intensity(df, intensity_name):\n",
    "    # Select intensity columns (from column 2 to column 13)\n",
    "    intensity_columns = df.columns[1:]\n",
    "\n",
    "    # Calculate the mean of intensity columns\n",
    "    averaged_intensity = df[intensity_columns].mean(axis=1)\n",
    "\n",
    "    # Create a new DataFrame with wavelength and averaged intensity\n",
    "    averaged_df = pd.DataFrame({'wavelength': df['wavelength'], intensity_name: averaged_intensity})\n",
    "\n",
    "    return averaged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6513913-8a90-4407-ab9e-a07a6bd25973",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE1_Averaged_df = average_intensity(df = SAMPLE1_Smoothed_df , intensity_name= 'sample1')\n",
    "SAMPLE2_Averaged_df = average_intensity(df = SAMPLE2_Smoothed_df , intensity_name= 'sample2')\n",
    "SAMPLE3_Averaged_df = average_intensity(df = SAMPLE3_Smoothed_df , intensity_name= 'sample3')\n",
    "SAMPLE4_Averaged_df = average_intensity(df = SAMPLE4_Smoothed_df , intensity_name= 'sample4')\n",
    "SAMPLE5_Averaged_df = average_intensity(df = SAMPLE5_Smoothed_df , intensity_name= 'sample5')\n",
    "SAMPLE6_Averaged_df = average_intensity(df = SAMPLE6_Smoothed_df , intensity_name= 'sample6')\n",
    "SAMPLE7_Averaged_df = average_intensity(df = SAMPLE7_Smoothed_df , intensity_name= 'sample7')\n",
    "SAMPLE8_Averaged_df = average_intensity(df = SAMPLE8_Smoothed_df , intensity_name= 'sample8')\n",
    "SAMPLE9_Averaged_df = average_intensity(df = SAMPLE9_Smoothed_df , intensity_name= 'sample9')\n",
    "SAMPLE10_Averaged_df = average_intensity(df = SAMPLE10_Smoothed_df , intensity_name= 'sample10')\n",
    "SAMPLE11_Averaged_df = average_intensity(df = SAMPLE11_Smoothed_df , intensity_name= 'sample11')\n",
    "SAMPLE12_Averaged_df = average_intensity(df = SAMPLE12_Smoothed_df , intensity_name= 'sample12')\n",
    "SAMPLE13_Averaged_df = average_intensity(df = SAMPLE13_Smoothed_df , intensity_name= 'sample13')\n",
    "SAMPLE14_Averaged_df = average_intensity(df = SAMPLE14_Smoothed_df , intensity_name= 'sample14')\n",
    "SAMPLE15_Averaged_df = average_intensity(df = SAMPLE15_Smoothed_df , intensity_name= 'sample15')\n",
    "SAMPLE16_Averaged_df = average_intensity(df = SAMPLE16_Smoothed_df , intensity_name= 'sample16')\n",
    "SAMPLE17_Averaged_df = average_intensity(df = SAMPLE17_Smoothed_df , intensity_name= 'sample17')\n",
    "\n",
    "print(SAMPLE1_Averaged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db436051-264a-41ad-a8ed-fdded9904e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE1_Averaged_full_df = average_intensity(df = SAMPLE1_Normalized_all_df , intensity_name= 'sample1')\n",
    "SAMPLE2_Averaged_full_df = average_intensity(df = SAMPLE2_Normalized_all_df , intensity_name= 'sample2')\n",
    "SAMPLE3_Averaged_full_df = average_intensity(df = SAMPLE3_Normalized_all_df , intensity_name= 'sample3')\n",
    "SAMPLE4_Averaged_full_df = average_intensity(df = SAMPLE4_Normalized_all_df , intensity_name= 'sample4')\n",
    "SAMPLE5_Averaged_full_df = average_intensity(df = SAMPLE5_Normalized_all_df , intensity_name= 'sample5')\n",
    "SAMPLE6_Averaged_full_df = average_intensity(df = SAMPLE6_Normalized_all_df , intensity_name= 'sample6')\n",
    "SAMPLE7_Averaged_full_df = average_intensity(df = SAMPLE7_Normalized_all_df , intensity_name= 'sample7')\n",
    "SAMPLE8_Averaged_full_df = average_intensity(df = SAMPLE8_Normalized_all_df , intensity_name= 'sample8')\n",
    "SAMPLE9_Averaged_full_df = average_intensity(df = SAMPLE9_Normalized_all_df , intensity_name= 'sample9')\n",
    "SAMPLE10_Averaged_full_df = average_intensity(df = SAMPLE10_Normalized_all_df , intensity_name= 'sample10')\n",
    "SAMPLE11_Averaged_full_df = average_intensity(df = SAMPLE11_Normalized_all_df , intensity_name= 'sample11')\n",
    "SAMPLE12_Averaged_full_df = average_intensity(df = SAMPLE12_Normalized_all_df , intensity_name= 'sample12')\n",
    "SAMPLE13_Averaged_full_df = average_intensity(df = SAMPLE13_Normalized_all_df , intensity_name= 'sample13')\n",
    "SAMPLE14_Averaged_full_df = average_intensity(df = SAMPLE14_Normalized_all_df , intensity_name= 'sample14')\n",
    "SAMPLE15_Averaged_full_df = average_intensity(df = SAMPLE15_Normalized_all_df , intensity_name= 'sample15')\n",
    "SAMPLE16_Averaged_full_df = average_intensity(df = SAMPLE16_Normalized_all_df , intensity_name= 'sample16')\n",
    "SAMPLE17_Averaged_full_df = average_intensity(df = SAMPLE17_Normalized_all_df , intensity_name= 'sample17')\n",
    "\n",
    "print(SAMPLE1_Averaged_full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06e11c3-46ad-44b2-bbf1-057e75908d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "Averaged_df_Plot = figure(title = 'Averaged Spectras' , x_axis_label = 'Wavelength' , y_axis_label = 'Intensity')\n",
    "\n",
    "Averaged_df_Plot.line(SAMPLE1_Averaged_df.wavelength,SAMPLE1_Averaged_df.sample1 , line_width = 2, color =\"blue\" )\n",
    "#####################################################################################################################\n",
    "Averaged_df_Plot.line(SAMPLE2_Averaged_df.wavelength,SAMPLE2_Averaged_df.sample2 , line_width = 2, color =\"orange\" )\n",
    "###############################################################################################################\n",
    "Averaged_df_Plot.line(SAMPLE3_Averaged_df.wavelength,SAMPLE3_Averaged_df.sample3 , line_width = 2, color =\"green\")\n",
    "######################################################################################################################\n",
    "Averaged_df_Plot.line(SAMPLE4_Averaged_df.wavelength,SAMPLE4_Averaged_df.sample4 , line_width = 2, color =\"red\")\n",
    "##############################################################################################################\n",
    "Averaged_df_Plot.line(SAMPLE5_Averaged_df.wavelength,SAMPLE5_Averaged_df.sample5 , line_width = 2, color =\"purple\")\n",
    "###############################################################################################################\n",
    "Averaged_df_Plot.line(SAMPLE6_Averaged_df.wavelength,SAMPLE6_Averaged_df.sample6 , line_width = 2, color =\"brown\")\n",
    "####################################################################################################################\n",
    "Averaged_df_Plot.line(SAMPLE7_Averaged_df.wavelength,SAMPLE7_Averaged_df.sample7 , line_width = 2, color =\"pink\")\n",
    "##################################################################################################################\n",
    "Averaged_df_Plot.line(SAMPLE8_Averaged_df.wavelength,SAMPLE8_Averaged_df.sample8 , line_width = 2, color =\"gray\")\n",
    "###################################################################################################################\n",
    "Averaged_df_Plot.line(SAMPLE9_Averaged_df.wavelength,SAMPLE9_Averaged_df.sample9 , line_width = 2, color =\"olive\")\n",
    "###################################################################################################################\n",
    "Averaged_df_Plot.line(SAMPLE10_Averaged_df.wavelength,SAMPLE10_Averaged_df.sample10 , line_width = 2, color =\"Cyan\")\n",
    "###################################################################################################################\n",
    "Averaged_df_Plot.line(SAMPLE11_Averaged_df.wavelength,SAMPLE11_Averaged_df.sample11 , line_width = 2, color =\"black\")\n",
    "###################################################################################################################\n",
    "Averaged_df_Plot.line(SAMPLE12_Averaged_df.wavelength,SAMPLE12_Averaged_df.sample12 , line_width = 2, color =\"tomato\")\n",
    "###################################################################################################################\n",
    "Averaged_df_Plot.line(SAMPLE13_Averaged_df.wavelength,SAMPLE13_Averaged_df.sample13 , line_width = 2, color =\"steelblue\")\n",
    "###################################################################################################################\n",
    "Averaged_df_Plot.line(SAMPLE14_Averaged_df.wavelength,SAMPLE14_Averaged_df.sample14 , line_width = 2, color =\"limegreen\")\n",
    "###################################################################################################################\n",
    "Averaged_df_Plot.line(SAMPLE15_Averaged_df.wavelength,SAMPLE15_Averaged_df.sample15 , line_width = 2, color =\"deeppink\")\n",
    "###################################################################################################################\n",
    "Averaged_df_Plot.line(SAMPLE16_Averaged_df.wavelength,SAMPLE16_Averaged_df.sample16 , line_width = 2, color =\"gold\")\n",
    "###################################################################################################################\n",
    "Averaged_df_Plot.line(SAMPLE17_Averaged_df.wavelength,SAMPLE17_Averaged_df.sample17 , line_width = 2, color =\"indigo\")\n",
    "###################################################################################################################\n",
    "\n",
    "Averaged_df_Plot.width = 900\n",
    "Averaged_df_Plot.height = 500\n",
    "show(Averaged_df_Plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b70cc1-0099-48e2-bde1-8f79c7e0d6b5",
   "metadata": {},
   "source": [
    "# Selection of ROI "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a02281c-d688-4651-9608-2461fd0c8d3e",
   "metadata": {},
   "source": [
    "Now , as we can see , we have datapoints from wavelength , in which we defined above , but our ROI is just one peak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8f0319-0924-496c-8aca-a2337604a69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For getting all datapoints \n",
    "\n",
    "Peak_Pos = '403.44'\n",
    "\n",
    "Peak_Min = 403.404\n",
    "Peak_Max = 403.479\n",
    "\n",
    "Element_name = 'Mn'\n",
    "\n",
    "SAMPLE1_Processed_Selectall_df = SAMPLE1_Smoothed_df[(SAMPLE1_Smoothed_df['wavelength'] >= Peak_Min) & (SAMPLE1_Smoothed_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE2_Processed_Selectall_df = SAMPLE2_Smoothed_df[(SAMPLE2_Smoothed_df['wavelength'] >= Peak_Min) & (SAMPLE2_Smoothed_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE3_Processed_Selectall_df = SAMPLE3_Smoothed_df[(SAMPLE3_Smoothed_df['wavelength'] >= Peak_Min) & (SAMPLE3_Smoothed_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE4_Processed_Selectall_df = SAMPLE4_Smoothed_df[(SAMPLE4_Smoothed_df['wavelength'] >= Peak_Min) & (SAMPLE4_Smoothed_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE5_Processed_Selectall_df = SAMPLE5_Smoothed_df[(SAMPLE5_Smoothed_df['wavelength'] >= Peak_Min) & (SAMPLE5_Smoothed_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE6_Processed_Selectall_df = SAMPLE6_Smoothed_df[(SAMPLE6_Smoothed_df['wavelength'] >= Peak_Min) & (SAMPLE6_Smoothed_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE7_Processed_Selectall_df = SAMPLE7_Smoothed_df[(SAMPLE7_Smoothed_df['wavelength'] >= Peak_Min) & (SAMPLE7_Smoothed_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE8_Processed_Selectall_df = SAMPLE8_Smoothed_df[(SAMPLE8_Smoothed_df['wavelength'] >= Peak_Min) & (SAMPLE8_Smoothed_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE9_Processed_Selectall_df = SAMPLE9_Smoothed_df[(SAMPLE9_Smoothed_df['wavelength'] >= Peak_Min) & (SAMPLE9_Smoothed_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE10_Processed_Selectall_df = SAMPLE10_Smoothed_df[(SAMPLE10_Smoothed_df['wavelength'] >= Peak_Min) & (SAMPLE10_Smoothed_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE11_Processed_Selectall_df = SAMPLE11_Smoothed_df[(SAMPLE11_Smoothed_df['wavelength'] >= Peak_Min) & (SAMPLE11_Smoothed_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE12_Processed_Selectall_df = SAMPLE12_Smoothed_df[(SAMPLE12_Smoothed_df['wavelength'] >= Peak_Min) & (SAMPLE12_Smoothed_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE13_Processed_Selectall_df = SAMPLE13_Smoothed_df[(SAMPLE13_Smoothed_df['wavelength'] >= Peak_Min) & (SAMPLE13_Smoothed_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE14_Processed_Selectall_df = SAMPLE14_Smoothed_df[(SAMPLE14_Smoothed_df['wavelength'] >= Peak_Min) & (SAMPLE14_Smoothed_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE15_Processed_Selectall_df = SAMPLE15_Smoothed_df[(SAMPLE15_Smoothed_df['wavelength'] >= Peak_Min) & (SAMPLE15_Smoothed_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE16_Processed_Selectall_df = SAMPLE16_Smoothed_df[(SAMPLE16_Smoothed_df['wavelength'] >= Peak_Min) & (SAMPLE16_Smoothed_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE17_Processed_Selectall_df = SAMPLE17_Smoothed_df[(SAMPLE17_Smoothed_df['wavelength'] >= Peak_Min) & (SAMPLE17_Smoothed_df['wavelength'] <= Peak_Max)]\n",
    "\n",
    "SAMPLE1_Processed_Selectall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54245132-004b-465d-b9e9-dbac20e33d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GAUSSIAN FITTING\n",
    "\n",
    "SAMPLE1_Fitted_Allpoints = fit_gaussian_profile(SAMPLE1_Processed_Selectall_df)\n",
    "SAMPLE2_Fitted_Allpoints = fit_gaussian_profile(SAMPLE2_Processed_Selectall_df)\n",
    "SAMPLE3_Fitted_Allpoints = fit_gaussian_profile(SAMPLE3_Processed_Selectall_df)\n",
    "SAMPLE4_Fitted_Allpoints = fit_gaussian_profile(SAMPLE4_Processed_Selectall_df)\n",
    "SAMPLE5_Fitted_Allpoints = fit_gaussian_profile(SAMPLE5_Processed_Selectall_df)\n",
    "SAMPLE6_Fitted_Allpoints = fit_gaussian_profile(SAMPLE6_Processed_Selectall_df)\n",
    "SAMPLE7_Fitted_Allpoints = (SAMPLE7_Processed_Selectall_df)\n",
    "SAMPLE8_Fitted_Allpoints = fit_gaussian_profile(SAMPLE8_Processed_Selectall_df)\n",
    "SAMPLE9_Fitted_Allpoints = fit_gaussian_profile(SAMPLE9_Processed_Selectall_df)\n",
    "SAMPLE10_Fitted_Allpoints = fit_gaussian_profile(SAMPLE10_Processed_Selectall_df)\n",
    "SAMPLE11_Fitted_Allpoints = fit_gaussian_profile(SAMPLE11_Processed_Selectall_df)\n",
    "SAMPLE12_Fitted_Allpoints = fit_gaussian_profile(SAMPLE12_Processed_Selectall_df)\n",
    "SAMPLE13_Fitted_Allpoints = fit_gaussian_profile(SAMPLE13_Processed_Selectall_df)\n",
    "SAMPLE14_Fitted_Allpoints = fit_gaussian_profile(SAMPLE14_Processed_Selectall_df)\n",
    "SAMPLE15_Fitted_Allpoints = fit_gaussian_profile(SAMPLE15_Processed_Selectall_df)\n",
    "SAMPLE16_Fitted_Allpoints = fit_gaussian_profile(SAMPLE16_Processed_Selectall_df)\n",
    "SAMPLE17_Fitted_Allpoints = (SAMPLE17_Processed_Selectall_df)\n",
    "\n",
    "SAMPLE1_Fitted_Allpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a693411-0de3-4f18-9ff5-f86283ca2155",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE1_Processed_Selectaverage_df = SAMPLE1_Averaged_df[(SAMPLE1_Averaged_df['wavelength'] >= Peak_Min) & (SAMPLE1_Averaged_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE2_Processed_Selectaverage_df = SAMPLE2_Averaged_df[(SAMPLE2_Averaged_df['wavelength'] >= Peak_Min) & (SAMPLE2_Averaged_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE3_Processed_Selectaverage_df = SAMPLE3_Averaged_df[(SAMPLE3_Averaged_df['wavelength'] >= Peak_Min) & (SAMPLE3_Averaged_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE4_Processed_Selectaverage_df = SAMPLE4_Averaged_df[(SAMPLE4_Averaged_df['wavelength'] >= Peak_Min) & (SAMPLE4_Averaged_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE5_Processed_Selectaverage_df = SAMPLE5_Averaged_df[(SAMPLE5_Averaged_df['wavelength'] >= Peak_Min) & (SAMPLE5_Averaged_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE6_Processed_Selectaverage_df = SAMPLE6_Averaged_df[(SAMPLE6_Averaged_df['wavelength'] >= Peak_Min) & (SAMPLE6_Averaged_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE7_Processed_Selectaverage_df = SAMPLE7_Averaged_df[(SAMPLE7_Averaged_df['wavelength'] >= Peak_Min) & (SAMPLE7_Averaged_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE8_Processed_Selectaverage_df = SAMPLE8_Averaged_df[(SAMPLE8_Averaged_df['wavelength'] >= Peak_Min) & (SAMPLE8_Averaged_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE9_Processed_Selectaverage_df = SAMPLE9_Averaged_df[(SAMPLE9_Averaged_df['wavelength'] >= Peak_Min) & (SAMPLE9_Averaged_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE10_Processed_Selectaverage_df = SAMPLE10_Averaged_df[(SAMPLE10_Averaged_df['wavelength'] >= Peak_Min) & (SAMPLE10_Averaged_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE11_Processed_Selectaverage_df = SAMPLE11_Averaged_df[(SAMPLE11_Averaged_df['wavelength'] >= Peak_Min) & (SAMPLE11_Averaged_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE12_Processed_Selectaverage_df = SAMPLE12_Averaged_df[(SAMPLE12_Averaged_df['wavelength'] >= Peak_Min) & (SAMPLE12_Averaged_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE13_Processed_Selectaverage_df = SAMPLE13_Averaged_df[(SAMPLE13_Averaged_df['wavelength'] >= Peak_Min) & (SAMPLE13_Averaged_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE14_Processed_Selectaverage_df = SAMPLE14_Averaged_df[(SAMPLE14_Averaged_df['wavelength'] >= Peak_Min) & (SAMPLE14_Averaged_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE15_Processed_Selectaverage_df = SAMPLE15_Averaged_df[(SAMPLE15_Averaged_df['wavelength'] >= Peak_Min) & (SAMPLE15_Averaged_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE16_Processed_Selectaverage_df = SAMPLE16_Averaged_df[(SAMPLE16_Averaged_df['wavelength'] >= Peak_Min) & (SAMPLE16_Averaged_df['wavelength'] <= Peak_Max)]\n",
    "SAMPLE17_Processed_Selectaverage_df = SAMPLE17_Averaged_df[(SAMPLE17_Averaged_df['wavelength'] >= Peak_Min) & (SAMPLE17_Averaged_df['wavelength'] <= Peak_Max)]\n",
    "\n",
    "SAMPLE1_Processed_Selectaverage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf2cb3a-dfc4-4b8c-b5bb-80cdbdbdde10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GAUSSIAN FITTING\n",
    "\n",
    "SAMPLE1_Fitted_Averagepoints = fit_gaussian_profile(SAMPLE1_Processed_Selectaverage_df)\n",
    "SAMPLE2_Fitted_Averagepoints = fit_gaussian_profile(SAMPLE2_Processed_Selectaverage_df)\n",
    "SAMPLE3_Fitted_Averagepoints = fit_gaussian_profile(SAMPLE3_Processed_Selectaverage_df)\n",
    "SAMPLE4_Fitted_Averagepoints = fit_gaussian_profile(SAMPLE4_Processed_Selectaverage_df)\n",
    "SAMPLE5_Fitted_Averagepoints = fit_gaussian_profile(SAMPLE5_Processed_Selectaverage_df)\n",
    "SAMPLE6_Fitted_Averagepoints = fit_gaussian_profile(SAMPLE6_Processed_Selectaverage_df)\n",
    "SAMPLE7_Fitted_Averagepoints = (SAMPLE7_Processed_Selectaverage_df)\n",
    "SAMPLE8_Fitted_Averagepoints = fit_gaussian_profile(SAMPLE8_Processed_Selectaverage_df)\n",
    "SAMPLE9_Fitted_Averagepoints = fit_gaussian_profile(SAMPLE9_Processed_Selectaverage_df)\n",
    "SAMPLE10_Fitted_Averagepoints = fit_gaussian_profile(SAMPLE10_Processed_Selectaverage_df)\n",
    "SAMPLE11_Fitted_Averagepoints = fit_gaussian_profile(SAMPLE11_Processed_Selectaverage_df)\n",
    "SAMPLE12_Fitted_Averagepoints = fit_gaussian_profile(SAMPLE12_Processed_Selectaverage_df)\n",
    "SAMPLE13_Fitted_Averagepoints = fit_gaussian_profile(SAMPLE13_Processed_Selectaverage_df)\n",
    "SAMPLE14_Fitted_Averagepoints = fit_gaussian_profile(SAMPLE14_Processed_Selectaverage_df)\n",
    "SAMPLE15_Fitted_Averagepoints = fit_gaussian_profile(SAMPLE15_Processed_Selectaverage_df)\n",
    "SAMPLE16_Fitted_Averagepoints = fit_gaussian_profile(SAMPLE16_Processed_Selectaverage_df)\n",
    "SAMPLE17_Fitted_Averagepoints = (SAMPLE17_Processed_Selectaverage_df)\n",
    "\n",
    "SAMPLE1_Fitted_Averagepoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7061d55-36f1-4f35-a233-e6e4bd6e96b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Processed_Select_df_Plot = figure(title = 'Si 288.157 - BATCH 2 PEAKS CONSIDERED' , x_axis_label = 'Wavelength' , y_axis_label = 'Intensity')\n",
    "\n",
    "# Processed_Select_df_Plot.line(SAMPLE1_Fitted_Averagepoints.wavelength,SAMPLE1_Fitted_Averagepoints.sample1 , line_width = 2, color =\"blue\",legend_label=\"SAMPLE 1\")\n",
    "# Processed_Select_df_Plot.line(SAMPLE1_Processed_Selectaverage_df.wavelength,SAMPLE1_Processed_Selectaverage_df.sample1 , line_width = 2, color =\"blue\",line_dash=\"dashed\")\n",
    "\n",
    "# ###################################################################################################################\n",
    "# Processed_Select_df_Plot.line(SAMPLE2_Fitted_Averagepoints.wavelength,SAMPLE2_Fitted_Averagepoints.sample2 , line_width = 2, color =\"orange\",legend_label=\"SAMPLE 2\")\n",
    "# Processed_Select_df_Plot.line(SAMPLE2_Processed_Selectaverage_df.wavelength,SAMPLE2_Processed_Selectaverage_df.sample2 , line_width = 2, color =\"orange\",line_dash=\"dashed\")\n",
    "\n",
    "# # ###############################################################################################################\n",
    "# Processed_Select_df_Plot.line(SAMPLE3_Fitted_Averagepoints.wavelength,SAMPLE3_Fitted_Averagepoints.sample3 , line_width = 2, color =\"green\",legend_label=\"SAMPLE 3\")\n",
    "# Processed_Select_df_Plot.line(SAMPLE3_Processed_Selectaverage_df.wavelength,SAMPLE3_Processed_Selectaverage_df.sample3 , line_width = 2, color =\"green\",line_dash=\"dashed\")\n",
    "\n",
    "# # # # ######################################################################################################################\n",
    "# Processed_Select_df_Plot.line(SAMPLE4_Fitted_Averagepoints.wavelength,SAMPLE4_Fitted_Averagepoints.sample4 , line_width = 2, color =\"red\",legend_label=\"SAMPLE 4\")\n",
    "# Processed_Select_df_Plot.line(SAMPLE4_Processed_Selectaverage_df.wavelength,SAMPLE4_Processed_Selectaverage_df.sample4 , line_width = 2, color =\"red\",line_dash=\"dashed\")\n",
    "\n",
    "# # #############################################################################################################\n",
    "# Processed_Select_df_Plot.line(SAMPLE5_Fitted_Averagepoints.wavelength,SAMPLE5_Fitted_Averagepoints.sample5 , line_width = 2, color =\"purple\",legend_label=\"SAMPLE 5\")\n",
    "# Processed_Select_df_Plot.line(SAMPLE5_Processed_Selectaverage_df.wavelength,SAMPLE5_Processed_Selectaverage_df.sample5 , line_width = 2, color =\"purple\",line_dash=\"dashed\")\n",
    "\n",
    "# #############################################################################################################\n",
    "# Processed_Select_df_Plot.line(SAMPLE6_Fitted_Averagepoints.wavelength,SAMPLE6_Fitted_Averagepoints.sample6 , line_width = 2, color =\"brown\",legend_label=\"SAMPLE 6\")\n",
    "# Processed_Select_df_Plot.line(SAMPLE6_Processed_Selectaverage_df.wavelength,SAMPLE6_Processed_Selectaverage_df.sample6 , line_width = 2, color =\"brown\",line_dash=\"dashed\")\n",
    "\n",
    "##################################################################################################################\n",
    "# Processed_Select_df_Plot.line(SAMPLE7_Fitted_Averagepoints.wavelength,SAMPLE7_Fitted_Averagepoints.sample7 , line_width = 2, color =\"pink\",legend_label=\"SAMPLE 7\")\n",
    "# Processed_Select_df_Plot.line(SAMPLE7_Processed_Selectaverage_df.wavelength,SAMPLE7_Processed_Selectaverage_df.sample7 , line_width = 2, color =\"pink\",line_dash=\"dashed\")\n",
    "\n",
    "# # #########################################################################################################\n",
    "# Processed_Select_df_Plot.line(SAMPLE8_Fitted_Averagepoints.wavelength,SAMPLE8_Fitted_Averagepoints.sample8 , line_width = 2, color =\"gray\",legend_label=\"SAMPLE 8\")\n",
    "# Processed_Select_df_Plot.line(SAMPLE8_Processed_Selectaverage_df.wavelength,SAMPLE8_Processed_Selectaverage_df.sample8 , line_width = 2, color =\"gray\",line_dash=\"dashed\")\n",
    "\n",
    "#########################################################################################################\n",
    "Processed_Select_df_Plot.line(SAMPLE9_Fitted_Averagepoints.wavelength,SAMPLE9_Fitted_Averagepoints.sample9 , line_width = 2, color =\"olive\",legend_label=\"SAMPLE 9\")\n",
    "Processed_Select_df_Plot.line(SAMPLE9_Processed_Selectaverage_df.wavelength,SAMPLE9_Processed_Selectaverage_df.sample9 , line_width = 2, color =\"olive\",line_dash=\"dashed\")\n",
    "\n",
    "# # ###################################################################################################################\n",
    "Processed_Select_df_Plot.line(SAMPLE10_Fitted_Averagepoints.wavelength,SAMPLE10_Fitted_Averagepoints.sample10 , line_width = 2, color =\"Cyan\",legend_label=\"SAMPLE 10\")\n",
    "Processed_Select_df_Plot.line(SAMPLE10_Processed_Selectaverage_df.wavelength,SAMPLE10_Processed_Selectaverage_df.sample10 , line_width = 2, color =\"Cyan\",line_dash=\"dashed\")\n",
    "\n",
    "# # # # # ###################################################################################################################\n",
    "Processed_Select_df_Plot.line(SAMPLE11_Fitted_Averagepoints.wavelength,SAMPLE11_Fitted_Averagepoints.sample11 , line_width = 2, color =\"black\",legend_label=\"SAMPLE 11\")\n",
    "Processed_Select_df_Plot.line(SAMPLE11_Processed_Selectaverage_df.wavelength,SAMPLE11_Processed_Selectaverage_df.sample11 , line_width = 2, color =\"black\",line_dash=\"dashed\")\n",
    "\n",
    "# # # ###################################################################################################################\n",
    "Processed_Select_df_Plot.line(SAMPLE12_Fitted_Averagepoints.wavelength,SAMPLE12_Fitted_Averagepoints.sample12 , line_width = 2, color =\"tomato\",legend_label=\"SAMPLE 12\")\n",
    "Processed_Select_df_Plot.line(SAMPLE12_Processed_Selectaverage_df.wavelength,SAMPLE12_Processed_Selectaverage_df.sample12 , line_width = 2, color =\"tomato\",line_dash=\"dashed\")\n",
    "\n",
    "# # ###################################################################################################################\n",
    "Processed_Select_df_Plot.line(SAMPLE13_Fitted_Averagepoints.wavelength,SAMPLE13_Fitted_Averagepoints.sample13 , line_width = 2, color =\"steelblue\",legend_label=\"SAMPLE 13\")\n",
    "Processed_Select_df_Plot.line(SAMPLE13_Processed_Selectaverage_df.wavelength,SAMPLE13_Processed_Selectaverage_df.sample13 , line_width = 2, color =\"steelblue\",line_dash=\"dashed\")\n",
    "\n",
    "# # # ##################################################################################################################\n",
    "Processed_Select_df_Plot.line(SAMPLE14_Fitted_Averagepoints.wavelength,SAMPLE14_Fitted_Averagepoints.sample14 , line_width = 2, color =\"limegreen\",legend_label=\"SAMPLE 14\")\n",
    "Processed_Select_df_Plot.line(SAMPLE14_Processed_Selectaverage_df.wavelength,SAMPLE14_Processed_Selectaverage_df.sample14 , line_width = 2, color =\"limegreen\",line_dash=\"dashed\")\n",
    "\n",
    "# # # ###################################################################################################################\n",
    "Processed_Select_df_Plot.line(SAMPLE15_Fitted_Averagepoints.wavelength,SAMPLE15_Fitted_Averagepoints.sample15 , line_width = 2, color =\"deeppink\",legend_label=\"SAMPLE 15\")\n",
    "Processed_Select_df_Plot.line(SAMPLE15_Processed_Selectaverage_df.wavelength,SAMPLE15_Processed_Selectaverage_df.sample15 , line_width = 2, color =\"deeppink\",line_dash=\"dashed\")\n",
    "\n",
    "# # ###################################################################################################################\n",
    "Processed_Select_df_Plot.line(SAMPLE16_Fitted_Averagepoints.wavelength,SAMPLE16_Fitted_Averagepoints.sample16 , line_width = 2, color =\"gold\",legend_label=\"SAMPLE 16\")\n",
    "Processed_Select_df_Plot.line(SAMPLE16_Processed_Selectaverage_df.wavelength,SAMPLE16_Processed_Selectaverage_df.sample16 , line_width = 2, color =\"gold\",line_dash=\"dashed\")\n",
    "\n",
    "# # # # # # # # # # # ###################################################################################################################\n",
    "Processed_Select_df_Plot.line(SAMPLE17_Fitted_Averagepoints.wavelength,SAMPLE17_Fitted_Averagepoints.sample17 , line_width = 2, color =\"indigo\",legend_label=\"SAMPLE 17\")\n",
    "Processed_Select_df_Plot.line(SAMPLE17_Processed_Selectaverage_df.wavelength,SAMPLE17_Processed_Selectaverage_df.sample17 , line_width = 2, color =\"indigo\",line_dash=\"dashed\")\n",
    "\n",
    "# # # #################################################################################################################\n",
    "\n",
    "Processed_Select_df_Plot.width = 500\n",
    "Processed_Select_df_Plot.height = 550\n",
    "\n",
    "show(Processed_Select_df_Plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d4fea7-a8f3-4274-b4b1-d48cb62bd587",
   "metadata": {},
   "source": [
    "# Extracting Peak Heights "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ce6ed9-7b09-41ba-9730-62928ae6cbce",
   "metadata": {},
   "source": [
    "As you see from the Pic above , even after normalizing the Spectra , there are few variations in the Intensities , Before passing them to regression step , the important step would be to do Outlier Removal of the Intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f67df2-75da-4b71-8c96-6ae7526a130c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_intensities(processed_df, threshold):\n",
    "    all_intensities = []\n",
    "\n",
    "    for col in processed_df.columns[1:]: #PEAK EXTRACTION\n",
    "        max_intensity = processed_df[col].max()\n",
    "        min_intensity = processed_df[col].min()\n",
    "        all_intensities.append(max_intensity)\n",
    "\n",
    "    all_intensities = np.array(all_intensities)\n",
    "    mean_intensities = np.mean(all_intensities)\n",
    "    std_intensities = np.std(all_intensities)\n",
    "    z_scores = np.abs((all_intensities - mean_intensities) / std_intensities)\n",
    "\n",
    "    cleaned_intensities = [intensity for intensity, z_score in zip(all_intensities, z_scores) if z_score < threshold]\n",
    "\n",
    "    return cleaned_intensities ,all_intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d209c601-24d7-4dc0-a6a9-e644219d24b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def calculate_peak_area_fwhm(signal, x_values):\n",
    "#     \"\"\"Calculate the area under the peak between the Full Width at Half Maximum (FWHM).\"\"\"\n",
    "#     # Find the maximum value of the signal\n",
    "#     max_value = np.max(signal)\n",
    "#     half_max = max_value / 2\n",
    "    \n",
    "#     # Find indices where the signal crosses half the maximum value\n",
    "#     above_half_max = signal >= half_max\n",
    "#     crossing_points = np.where(above_half_max)[0]\n",
    "    \n",
    "#     if len(crossing_points) < 2:\n",
    "#         # Not enough points to define FWHM\n",
    "#         return 0, None, None\n",
    "\n",
    "#     # Determine FWHM indices\n",
    "#     fwhm_start_idx = crossing_points[0]\n",
    "#     fwhm_end_idx = crossing_points[-1]\n",
    "    \n",
    "#     # Extract the portion of the signal between the FWHM points\n",
    "#     fwhm_signal = signal[fwhm_start_idx:fwhm_end_idx+1]\n",
    "#     fwhm_x_values = x_values[fwhm_start_idx:fwhm_end_idx+1]\n",
    "    \n",
    "#     # Calculate the area under the curve using the trapezoidal rule\n",
    "#     peak_area = np.trapz(fwhm_signal, fwhm_x_values)\n",
    "    \n",
    "#     return peak_area, fwhm_x_values, fwhm_signal\n",
    "\n",
    "# def clean_intensities(processed_df, threshold):\n",
    "#     all_areas = []\n",
    "\n",
    "#     # first column is not part of the signal data (e.g., time or index)\n",
    "#     x_values = processed_df.iloc[:, 0].values\n",
    "\n",
    "#     for col in processed_df.columns[1:]:\n",
    "#         signal = processed_df[col].values\n",
    "#         peak_area, fwhm_x_values, fwhm_signal = calculate_peak_area_fwhm(signal, x_values)\n",
    "#         all_areas.append(peak_area)\n",
    "\n",
    "#         # Plotting the signal and FWHM\n",
    "#         # plt.figure(figsize=(10, 6))\n",
    "#         # plt.plot(x_values, signal, label='Signal')\n",
    "#         # if fwhm_x_values is not None and fwhm_signal is not None:\n",
    "#         #     plt.fill_between(fwhm_x_values, fwhm_signal, alpha=0.3, label='FWHM Area')\n",
    "#         #     plt.axhline(y=np.max(signal) / 2, color='r', linestyle='--', label='FWHM Half-Max')\n",
    "#         # plt.xlabel('Wavelength')\n",
    "#         # plt.ylabel('Intensity')\n",
    "#         # plt.title(f'Signal and FWHM Area for {col}')\n",
    "#         # plt.legend()\n",
    "#         # # plt.show()\n",
    "\n",
    "#     all_areas = np.array(all_areas)\n",
    "#     mean_areas = np.mean(all_areas)\n",
    "#     std_areas = np.std(all_areas)\n",
    "#     z_scores = np.abs((all_areas - mean_areas) / std_areas)\n",
    "\n",
    "#     cleaned_areas = [area for area, z_score in zip(all_areas, z_scores) if z_score < threshold]\n",
    "\n",
    "#     return cleaned_areas, all_areas\n",
    "\n",
    "# # Example usage:\n",
    "# # processed_df = pd.DataFrame({'Time': time_data, 'Signal1': signal1_data, 'Signal2': signal2_data, ...})\n",
    "# # cleaned_areas, all_areas = clean_intensities(processed_df, threshold=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa613733-08df-45c0-b4ce-87764c097235",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE1_Selectedall_Intensities = clean_intensities(processed_df=SAMPLE1_Fitted_Allpoints, threshold=3)[0]\n",
    "SAMPLE2_Selectedall_Intensities = clean_intensities(processed_df=SAMPLE2_Fitted_Allpoints, threshold=3)[0]\n",
    "SAMPLE3_Selectedall_Intensities = clean_intensities(processed_df=SAMPLE3_Fitted_Allpoints, threshold=3)[0]\n",
    "SAMPLE4_Selectedall_Intensities = clean_intensities(processed_df=SAMPLE4_Fitted_Allpoints, threshold=3)[0]\n",
    "SAMPLE5_Selectedall_Intensities = clean_intensities(processed_df=SAMPLE5_Fitted_Allpoints, threshold=3)[0]\n",
    "SAMPLE6_Selectedall_Intensities = clean_intensities(processed_df=SAMPLE6_Fitted_Allpoints, threshold=3)[0]\n",
    "SAMPLE7_Selectedall_Intensities = clean_intensities(processed_df=SAMPLE7_Fitted_Allpoints, threshold=3)[0]\n",
    "SAMPLE8_Selectedall_Intensities = clean_intensities(processed_df=SAMPLE8_Fitted_Allpoints, threshold=3)[0]\n",
    "SAMPLE9_Selectedall_Intensities = clean_intensities(processed_df=SAMPLE9_Fitted_Allpoints, threshold=3)[0]\n",
    "SAMPLE10_Selectedall_Intensities = clean_intensities(processed_df=SAMPLE10_Fitted_Allpoints, threshold=3)[0]\n",
    "SAMPLE11_Selectedall_Intensities = clean_intensities(processed_df=SAMPLE11_Fitted_Allpoints, threshold=3)[0]\n",
    "SAMPLE12_Selectedall_Intensities = clean_intensities(processed_df=SAMPLE12_Fitted_Allpoints, threshold=3)[0]\n",
    "SAMPLE13_Selectedall_Intensities = clean_intensities(processed_df=SAMPLE13_Fitted_Allpoints, threshold=3)[0]\n",
    "SAMPLE14_Selectedall_Intensities = clean_intensities(processed_df=SAMPLE14_Fitted_Allpoints, threshold=3)[0]\n",
    "SAMPLE15_Selectedall_Intensities = clean_intensities(processed_df=SAMPLE15_Fitted_Allpoints, threshold=3)[0]\n",
    "SAMPLE16_Selectedall_Intensities = clean_intensities(processed_df=SAMPLE16_Fitted_Allpoints, threshold=3)[0]\n",
    "SAMPLE17_Selectedall_Intensities = clean_intensities(processed_df=SAMPLE17_Fitted_Allpoints, threshold=3)[0]\n",
    "\n",
    "print(SAMPLE1_Selectedall_Intensities)\n",
    "print(SAMPLE2_Selectedall_Intensities)\n",
    "print(SAMPLE3_Selectedall_Intensities)\n",
    "print(SAMPLE4_Selectedall_Intensities)\n",
    "print(SAMPLE5_Selectedall_Intensities)\n",
    "print(SAMPLE6_Selectedall_Intensities)\n",
    "print(SAMPLE7_Selectedall_Intensities)\n",
    "print(SAMPLE8_Selectedall_Intensities)\n",
    "print(SAMPLE9_Selectedall_Intensities)\n",
    "print(SAMPLE10_Selectedall_Intensities)\n",
    "print(SAMPLE11_Selectedall_Intensities)\n",
    "print(SAMPLE12_Selectedall_Intensities)\n",
    "print(SAMPLE13_Selectedall_Intensities)\n",
    "print(SAMPLE14_Selectedall_Intensities)\n",
    "print(SAMPLE15_Selectedall_Intensities)\n",
    "print(SAMPLE16_Selectedall_Intensities)\n",
    "print(SAMPLE17_Selectedall_Intensities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff12660b-a97a-4d24-ae02-2ac410dcd8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE1_Selected_Intensities = clean_intensities(processed_df=SAMPLE1_Fitted_Averagepoints, threshold=3)[1]\n",
    "SAMPLE2_Selected_Intensities = clean_intensities(processed_df=SAMPLE2_Fitted_Averagepoints, threshold=3)[1]\n",
    "SAMPLE3_Selected_Intensities = clean_intensities(processed_df=SAMPLE3_Fitted_Averagepoints, threshold=3)[1]\n",
    "SAMPLE4_Selected_Intensities = clean_intensities(processed_df=SAMPLE4_Fitted_Averagepoints, threshold=3)[1]\n",
    "SAMPLE5_Selected_Intensities = clean_intensities(processed_df=SAMPLE5_Fitted_Averagepoints, threshold=3)[1]\n",
    "SAMPLE6_Selected_Intensities = clean_intensities(processed_df=SAMPLE6_Fitted_Averagepoints, threshold=3)[1]\n",
    "SAMPLE7_Selected_Intensities = clean_intensities(processed_df=SAMPLE7_Fitted_Averagepoints, threshold=3)[1]\n",
    "SAMPLE8_Selected_Intensities = clean_intensities(processed_df=SAMPLE8_Fitted_Averagepoints, threshold=3)[1]\n",
    "SAMPLE9_Selected_Intensities = clean_intensities(processed_df=SAMPLE9_Fitted_Averagepoints, threshold=3)[1]\n",
    "SAMPLE10_Selected_Intensities = clean_intensities(processed_df=SAMPLE10_Fitted_Averagepoints, threshold=3)[1]\n",
    "SAMPLE11_Selected_Intensities = clean_intensities(processed_df=SAMPLE11_Fitted_Averagepoints, threshold=3)[1]\n",
    "SAMPLE12_Selected_Intensities = clean_intensities(processed_df=SAMPLE12_Fitted_Averagepoints, threshold=3)[1]\n",
    "SAMPLE13_Selected_Intensities = clean_intensities(processed_df=SAMPLE13_Fitted_Averagepoints, threshold=3)[1]\n",
    "SAMPLE14_Selected_Intensities = clean_intensities(processed_df=SAMPLE14_Fitted_Averagepoints, threshold=3)[1]\n",
    "SAMPLE15_Selected_Intensities = clean_intensities(processed_df=SAMPLE15_Fitted_Averagepoints, threshold=3)[1]\n",
    "SAMPLE16_Selected_Intensities = clean_intensities(processed_df=SAMPLE16_Fitted_Averagepoints, threshold=3)[1]\n",
    "SAMPLE17_Selected_Intensities = clean_intensities(processed_df=SAMPLE17_Fitted_Averagepoints, threshold=3)[1]\n",
    "\n",
    "\n",
    "print(SAMPLE1_Selected_Intensities)\n",
    "print(SAMPLE2_Selected_Intensities)\n",
    "print(SAMPLE3_Selected_Intensities)\n",
    "print(SAMPLE4_Selected_Intensities)\n",
    "print(SAMPLE5_Selected_Intensities)\n",
    "print(SAMPLE6_Selected_Intensities)\n",
    "print(SAMPLE7_Selected_Intensities)\n",
    "print(SAMPLE8_Selected_Intensities)\n",
    "print(SAMPLE9_Selected_Intensities)\n",
    "print(SAMPLE10_Selected_Intensities)\n",
    "print(SAMPLE11_Selected_Intensities)\n",
    "print(SAMPLE12_Selected_Intensities)\n",
    "print(SAMPLE13_Selected_Intensities)\n",
    "print(SAMPLE14_Selected_Intensities)\n",
    "print(SAMPLE15_Selected_Intensities)\n",
    "print(SAMPLE16_Selected_Intensities)\n",
    "print(SAMPLE17_Selected_Intensities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8988857-4b42-4c16-b02d-594cb29f3929",
   "metadata": {},
   "source": [
    "# RMS CALCULATION & CHOOSING DECISION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cea8fdd-6067-4c9d-891c-6adae3ead011",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_rms_of_noise(df):\n",
    "    # Filter the rows where wavelength is less than 215\n",
    "    noise_df = df[df['wavelength'] < 215]\n",
    "    \n",
    "    # Extract the column with measurements (assuming it's the second column)\n",
    "    measurement_column = noise_df.columns[1]\n",
    "    noise_values = noise_df[measurement_column]\n",
    "    \n",
    "    # Calculate the RMS\n",
    "    rms = np.sqrt(np.mean(np.square(noise_values)))\n",
    "    \n",
    "    return rms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa52ed3e-cc33-4bec-be32-8c1f808e21da",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE1_Averaged_NoiseRMS = calculate_rms_of_noise(SAMPLE1_Averaged_full_df)\n",
    "SAMPLE2_Averaged_NoiseRMS = calculate_rms_of_noise(SAMPLE2_Averaged_full_df)\n",
    "SAMPLE3_Averaged_NoiseRMS = calculate_rms_of_noise(SAMPLE3_Averaged_full_df)\n",
    "SAMPLE4_Averaged_NoiseRMS = calculate_rms_of_noise(SAMPLE4_Averaged_full_df)\n",
    "SAMPLE5_Averaged_NoiseRMS = calculate_rms_of_noise(SAMPLE5_Averaged_full_df)\n",
    "SAMPLE6_Averaged_NoiseRMS = calculate_rms_of_noise(SAMPLE6_Averaged_full_df)\n",
    "SAMPLE7_Averaged_NoiseRMS = calculate_rms_of_noise(SAMPLE7_Averaged_full_df)\n",
    "SAMPLE8_Averaged_NoiseRMS = calculate_rms_of_noise(SAMPLE8_Averaged_full_df)\n",
    "SAMPLE9_Averaged_NoiseRMS = calculate_rms_of_noise(SAMPLE9_Averaged_full_df)\n",
    "SAMPLE10_Averaged_NoiseRMS = calculate_rms_of_noise(SAMPLE10_Averaged_full_df)\n",
    "SAMPLE11_Averaged_NoiseRMS = calculate_rms_of_noise(SAMPLE11_Averaged_full_df)\n",
    "SAMPLE12_Averaged_NoiseRMS = calculate_rms_of_noise(SAMPLE12_Averaged_full_df)\n",
    "SAMPLE13_Averaged_NoiseRMS = calculate_rms_of_noise(SAMPLE13_Averaged_full_df)\n",
    "SAMPLE14_Averaged_NoiseRMS = calculate_rms_of_noise(SAMPLE14_Averaged_full_df)\n",
    "SAMPLE15_Averaged_NoiseRMS = calculate_rms_of_noise(SAMPLE15_Averaged_full_df)\n",
    "SAMPLE16_Averaged_NoiseRMS = calculate_rms_of_noise(SAMPLE16_Averaged_full_df)\n",
    "SAMPLE17_Averaged_NoiseRMS = calculate_rms_of_noise(SAMPLE17_Averaged_full_df)\n",
    "\n",
    "SAMPLE1_Averaged_NoiseRMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fc2bac-04b4-4478-8343-76ca57355467",
   "metadata": {},
   "outputs": [],
   "source": [
    "Noise_Threshold = 6\n",
    "\n",
    "if SAMPLE1_Selected_Intensities <= Noise_Threshold * (SAMPLE1_Averaged_NoiseRMS):\n",
    "    print (\"SAMPLE 1 NOT SELECTED\")\n",
    "\n",
    "if SAMPLE2_Selected_Intensities <= Noise_Threshold * (SAMPLE2_Averaged_NoiseRMS):\n",
    "    print(\"SAMPLE 2 NOT SELECTED\")\n",
    "\n",
    "if SAMPLE3_Selected_Intensities <= Noise_Threshold * (SAMPLE3_Averaged_NoiseRMS):\n",
    "    print(\"SAMPLE 3 NOT SELECTED\")\n",
    "\n",
    "if SAMPLE4_Selected_Intensities <= Noise_Threshold * (SAMPLE4_Averaged_NoiseRMS):\n",
    "    print(\"SAMPLE 4 NOT SELECTED\")\n",
    "\n",
    "if SAMPLE5_Selected_Intensities <= Noise_Threshold * (SAMPLE5_Averaged_NoiseRMS):\n",
    "    print(\"SAMPLE 5 NOT SELECTED\")\n",
    "\n",
    "if SAMPLE6_Selected_Intensities <= Noise_Threshold * (SAMPLE6_Averaged_NoiseRMS):\n",
    "    print(\"SAMPLE 6 NOT SELECTED\")\n",
    "\n",
    "if SAMPLE7_Selected_Intensities <= Noise_Threshold * (SAMPLE7_Averaged_NoiseRMS):\n",
    "    print(\"SAMPLE 7 NOT SELECTED\")\n",
    "\n",
    "if SAMPLE8_Selected_Intensities <= Noise_Threshold * (SAMPLE8_Averaged_NoiseRMS):\n",
    "    print(\"SAMPLE 8 NOT SELECTED\")\n",
    "\n",
    "if SAMPLE9_Selected_Intensities <= Noise_Threshold * (SAMPLE9_Averaged_NoiseRMS):\n",
    "    print(\"SAMPLE 9 NOT SELECTED\")\n",
    "\n",
    "if SAMPLE10_Selected_Intensities <= Noise_Threshold * (SAMPLE10_Averaged_NoiseRMS):\n",
    "    print(\"SAMPLE 10 NOT SELECTED\")\n",
    "\n",
    "if SAMPLE11_Selected_Intensities <= Noise_Threshold * (SAMPLE11_Averaged_NoiseRMS):\n",
    "    print(\"SAMPLE 11 NOT SELECTED\")\n",
    "\n",
    "if SAMPLE12_Selected_Intensities <= Noise_Threshold * (SAMPLE12_Averaged_NoiseRMS):\n",
    "    print(\"SAMPLE 12 NOT SELECTED\")\n",
    "\n",
    "if SAMPLE13_Selected_Intensities <= Noise_Threshold * (SAMPLE13_Averaged_NoiseRMS):\n",
    "    print(\"SAMPLE 13 NOT SELECTED\")\n",
    "\n",
    "if SAMPLE14_Selected_Intensities <= Noise_Threshold * (SAMPLE14_Averaged_NoiseRMS):\n",
    "    print(\"SAMPLE 14 NOT SELECTED\")\n",
    "\n",
    "if SAMPLE15_Selected_Intensities <= Noise_Threshold * (SAMPLE15_Averaged_NoiseRMS):\n",
    "    print(\"SAMPLE 15 NOT SELECTED\")\n",
    "\n",
    "if SAMPLE16_Selected_Intensities <= Noise_Threshold * (SAMPLE16_Averaged_NoiseRMS):\n",
    "    print(\"SAMPLE 16 NOT SELECTED\")\n",
    "\n",
    "if SAMPLE17_Selected_Intensities <= Noise_Threshold * (SAMPLE17_Averaged_NoiseRMS):\n",
    "    print(\"SAMPLE 17 NOT SELECTED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c1497f-52c1-402b-ace7-5f8cbce55e33",
   "metadata": {},
   "source": [
    "# REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089a1311-2364-4062-893a-57bfbf25bcde",
   "metadata": {},
   "source": [
    "At the last , now we have list we have selected intensities for each sample , also we have the concentration values per element of each sample , we can now do the regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b5f2a2-f117-4133-ac2b-9d0c2ceeaf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression for C , Mn , Si , Al ,Cr ,Cu , Ni , Nb ,Mo ,Ti (BATCH 2 and 3 COMBINED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1b647a-68ea-467e-9fe6-935b99e02a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_data = {\n",
    "    'Intensity': [\n",
    "        SAMPLE1_Selectedall_Intensities,\n",
    "        SAMPLE2_Selectedall_Intensities,\n",
    "        SAMPLE3_Selectedall_Intensities,\n",
    "        SAMPLE4_Selectedall_Intensities,\n",
    "        SAMPLE5_Selectedall_Intensities,\n",
    "        SAMPLE6_Selectedall_Intensities,\n",
    "        SAMPLE7_Selectedall_Intensities,\n",
    "        SAMPLE8_Selectedall_Intensities,\n",
    "        SAMPLE9_Selectedall_Intensities,\n",
    "        SAMPLE10_Selectedall_Intensities,\n",
    "        SAMPLE11_Selectedall_Intensities,\n",
    "        SAMPLE12_Selectedall_Intensities,\n",
    "        SAMPLE13_Selectedall_Intensities,\n",
    "        SAMPLE14_Selectedall_Intensities,\n",
    "        SAMPLE15_Selectedall_Intensities,\n",
    "        SAMPLE16_Selectedall_Intensities,\n",
    "        SAMPLE17_Selectedall_Intensities\n",
    "    ],\n",
    "    \n",
    "    'C_concentration':  [\n",
    "    0.15, 0.15, 0.16, 0.23, 0.21, 0.07, 0.003, 0.06, \n",
    "    0.1222, 0.0847, 0.2990, 0.0032, 0.2734, 0.8027, 0.6353, 0.6632, 0.0943\n",
    "    ],\n",
    "\n",
    "    'Mn_concentration':  [\n",
    "    1.9, 1.8, 2.3, 1.2, 1.9, 2.3, 0.1, 1.1,\n",
    "    0.571, 0.489, 0.622, 0.000, 0.347, 0.428, 0.473, 0.515, 0.208\n",
    "    ],\n",
    "\n",
    "    'Si_concentration':  [\n",
    "    0.3, 0.3, 0.5, 0.2, 1.8, 0.2, 0.0, 0.4,\n",
    "    0.13, 0.10, 0.32, 0.00, 0.09, 0.67, 0.58, 0.33, 0.00\n",
    "    ],\n",
    "\n",
    "    'Al_concentration':  [\n",
    "    0.04, 0.04, 0.69, 0.03, 0.04, 0.04, 0.02, 0.04,\n",
    "    0.280, 0.413, 3.430, 0.000, 0.000, 0.775, 1.995, 0.029, 0.000\n",
    "    ],\n",
    "\n",
    "    'Cr_concentration':  [\n",
    "    0.41, 0.42, 0.70, 0.14, 0.05, 0.60, 0.03, 0.03,\n",
    "    0.550, 0.020, 2.150, 0.000, 0.021, 0.591, 0.184, 0.194, 0.007\n",
    "    ],\n",
    "\n",
    "    'Cu_concentration':  [\n",
    "    0.02, 0.02, 0.03, 0.02, 0.03, 0.02, 0.01, 0.01,\n",
    "    0.036, 0.101, 0.049, 0.006, 0.044, 0.220, 0.430, 1.585, 0.067\n",
    "    ],\n",
    "    'Ni_concentration':  [\n",
    "    0.030, 0.037, 0.048, 0.020, 0.037, 0.040, 0.020, 0.010,\n",
    "    0.000, 0.000, 0.000, 0.000, 0.047, 0.054, 0.075, 0.077, 0.023\n",
    "    ],\n",
    "    'Nb_concentration':  [\n",
    "    0.006, 0.006, 0.032, 0.001, 0.056, 0.001, 0.001, 0.046,\n",
    "    0.0191, 0.0000, 0.0337, 0.0000, 0.0021, 0.0169, 0.0136, 0.0000, 0.0030\n",
    "    ],\n",
    "    'Mo_concentration':  [\n",
    "    0.101, 0.105, 0.023, 0.000, 0.006, 0.020, 0.005, 0.002,\n",
    "    0.000, 0.007, 0.126, 0.007, 0.008, 0.010, 0.005, 0.021, 0.007\n",
    "    ],\n",
    "    'Ti_concentration':  [\n",
    "    0.044, 0.037, 0.025, 0.034, 0.014, 0.051, 0.068, 0.028,\n",
    "    0.0353, 0.0086, 0.0502, 0.0000, 0.0000, 0.0181, 0.0158, 0.0067, 0.0000\n",
    "    ]\n",
    "    }\n",
    "\n",
    "# Creating the DataFrame\n",
    "calibration_dataframe = pd.DataFrame(intensity_data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(calibration_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cb2f52-8b03-4b29-a911-92b098852fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_dataframe_np = calibration_dataframe.to_numpy()\n",
    "calibration_dataframe_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28c93cd-4a0a-41ad-8f75-edaa291267a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting first 8 rows for training\n",
    "\n",
    "sample_indices_batch1 = [ 1,2 ,3 ,4,5,6,7,8] #Actual Samples to Include\n",
    "\n",
    "indices_batch1 = [x - 1 for x in sample_indices_batch1]\n",
    "\n",
    "\n",
    "X_train_1 = calibration_dataframe['Intensity'].values[indices_batch1]\n",
    "y_train_1 = calibration_dataframe['Mn_concentration'].values[indices_batch1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de3086a-1629-474c-817f-f604d6e21d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting last 9  rows for training\n",
    "sample_indices_batch2 = [9 ,10,11,12 ,13,14,15,16,17] #Actual Samples to Include\n",
    "indices_batch2 = [y - 1 for y in sample_indices_batch2]\n",
    "\n",
    "\n",
    "X_train_2 = calibration_dataframe['Intensity'].values[indices_batch2]\n",
    "y_train_2 = calibration_dataframe['Mn_concentration'].values[indices_batch2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75758dd-9a67-46e7-9540-6ce3eacc6d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting last 9  rows for training\n",
    "sample_indices_batch3 = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17] #Actual Samples to Include\n",
    "indices_batch3 = [z - 1 for z in sample_indices_batch3]\n",
    "\n",
    "\n",
    "X_train_3 = calibration_dataframe['Intensity'].values[indices_batch3]\n",
    "y_train_3 = calibration_dataframe['Mn_concentration'].values[indices_batch3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b0d4ae-5e7f-4861-b9ab-0e6ad71f1df2",
   "metadata": {},
   "source": [
    "# BATCH 2 - CALIBRATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3227efeb-a8c7-4f70-b51f-af5ad9ec8cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt_1\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "# Flatten X_train to fit the model\n",
    "mean_intensity_1 = np.array([np.mean(sample_1) for sample_1 in X_train_1])\n",
    "std_dev_intensity_1 = np.array([np.std(sample_1) for sample_1 in X_train_1])\n",
    "\n",
    "print (mean_intensity_1)\n",
    "\n",
    "X_flattened_1_x1 = [mean_intensity_1[0]] \n",
    "X_flattened_1_x2 = [mean_intensity_1[1]] \n",
    "X_flattened_1_x3 = [mean_intensity_1[2]] \n",
    "X_flattened_1_x4 = [mean_intensity_1[3]] \n",
    "X_flattened_1_x5 = [mean_intensity_1[4]] \n",
    "X_flattened_1_x6 = [mean_intensity_1[5]] \n",
    "X_flattened_1_x7 = [mean_intensity_1[6]] \n",
    "X_flattened_1_x8 = [mean_intensity_1[7]] \n",
    "\n",
    "\n",
    "Y_flattened_1_y1 = [y_train_1[0]] \n",
    "Y_flattened_1_y2 = [y_train_1[1]] \n",
    "Y_flattened_1_y3 = [y_train_1[2]] \n",
    "Y_flattened_1_y4 = [y_train_1[3]] \n",
    "Y_flattened_1_y5 = [y_train_1[4]] \n",
    "Y_flattened_1_y6 = [y_train_1[5]] \n",
    "Y_flattened_1_y7 = [y_train_1[6]] \n",
    "Y_flattened_1_y8 = [y_train_1[7]] \n",
    "\n",
    "\n",
    "\n",
    "X_flattened_1 = np.concatenate([\n",
    "                    np.array(X_flattened_1_x1).reshape(-1,1), \n",
    "                    np.array(X_flattened_1_x2).reshape(-1,1),\n",
    "                    np.array(X_flattened_1_x3).reshape(-1,1),\n",
    "                    np.array(X_flattened_1_x4).reshape(-1,1),\n",
    "                    np.array(X_flattened_1_x5).reshape(-1,1),\n",
    "                    np.array(X_flattened_1_x6).reshape(-1,1),\n",
    "                    np.array(X_flattened_1_x7).reshape(-1,1),\n",
    "                    np.array(X_flattened_1_x8).reshape(-1,1)\n",
    "                    ])\n",
    "\n",
    "Y_flattened_1 = np.concatenate([\n",
    "                    np.array(Y_flattened_1_y1).reshape(-1,1), \n",
    "                    np.array(Y_flattened_1_y2).reshape(-1,1),\n",
    "                    np.array(Y_flattened_1_y3).reshape(-1,1),\n",
    "                    np.array(Y_flattened_1_y4).reshape(-1,1),\n",
    "                    np.array(Y_flattened_1_y5).reshape(-1,1),\n",
    "                    np.array(Y_flattened_1_y6).reshape(-1,1),\n",
    "                    np.array(Y_flattened_1_y7).reshape(-1,1),\n",
    "                    np.array(Y_flattened_1_y8).reshape(-1,1)\n",
    "                    ])\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "model_1 = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "model_1.fit(X_flattened_1, Y_flattened_1)\n",
    "\n",
    "\n",
    "# Compute R2 and RMSE\n",
    "r2_1 = model_1.score(X_flattened_1,Y_flattened_1)\n",
    "rmse_1 = np.sqrt(mean_squared_error(X_flattened_1,Y_flattened_1))\n",
    "\n",
    "# Get the model coefficients and intercept\n",
    "coefficients_1 = model_1.coef_\n",
    "intercept_1 = model_1.intercept_\n",
    "\n",
    "\n",
    "# # Plotting with horizontal error bars\n",
    "plt_1.figure(figsize=(8, 5))\n",
    "\n",
    "plt_1.errorbar(X_flattened_1_x1,Y_flattened_1_y1 , xerr=std_dev_intensity_1[0], fmt='o', color='blue', ecolor='black', capsize=3,label='SAMPLE 1')\n",
    "plt_1.errorbar(X_flattened_1_x2,Y_flattened_1_y2 , xerr=std_dev_intensity_1[1], fmt='o', color='orange', ecolor='black', capsize=3,label='SAMPLE 2')\n",
    "plt_1.errorbar(X_flattened_1_x3,Y_flattened_1_y3 , xerr=std_dev_intensity_1[2], fmt='o', color='green', ecolor='black', capsize=3,label='SAMPLE 3')\n",
    "plt_1.errorbar(X_flattened_1_x4,Y_flattened_1_y4 , xerr=std_dev_intensity_1[3], fmt='o', color='red', ecolor='black', capsize=3,label='SAMPLE 4')\n",
    "plt_1.errorbar(X_flattened_1_x5,Y_flattened_1_y5 , xerr=std_dev_intensity_1[4], fmt='o', color='purple', ecolor='black', capsize=3,label='SAMPLE 5')\n",
    "plt_1.errorbar(X_flattened_1_x6,Y_flattened_1_y6 , xerr=std_dev_intensity_1[5], fmt='o', color='brown', ecolor='black', capsize=3,label='SAMPLE 6')\n",
    "plt_1.errorbar(X_flattened_1_x7,Y_flattened_1_y7 , xerr=std_dev_intensity_1[6], fmt='o', color='pink', ecolor='black', capsize=3,label='SAMPLE 7')\n",
    "plt_1.errorbar(X_flattened_1_x8,Y_flattened_1_y8 , xerr=std_dev_intensity_1[7], fmt='o', color='gray', ecolor='black', capsize=3,label='SAMPLE 8')\n",
    "\n",
    "plt_1.plot(X_flattened_1,model_1.predict(X_flattened_1), color ='black' , linewidth = 0.5)\n",
    "\n",
    "\n",
    "title_1 = (Element_name) + ' ' + (Peak_Pos)+ ' - BATCH 2 REFERENCE'\n",
    "plt_1.xlabel('Intensities (a.u.)')\n",
    "plt_1.ylabel('Concentration (%) ')\n",
    "plt_1.title(title_1)\n",
    "plt_1.legend(bbox_to_anchor=(1, 1), loc='upper left')\n",
    "\n",
    "plt_1.text(0.85, 0.9, f'y = {coefficients_1:}x + {intercept_1:}', transform=plt.gcf().transFigure, fontsize=10)\n",
    "plt_1.text(0.92,0.05, f'R^2 = {r2_1:.2f}\\nRMSE = {rmse_1:.2f}', transform=plt.gcf().transFigure, fontsize=10)\n",
    "plt_1.savefig((title_1)+ \".png\" ,dpi = 1200 , bbox_inches='tight')\n",
    "\n",
    "plt_1.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f41a1e-9983-40ff-bd11-665b5804ac75",
   "metadata": {},
   "source": [
    "# BATCH 2 VALIDATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59bbb7b-9376-4efb-94f8-31347a759278",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt_4\n",
    "\n",
    "\n",
    "X_validation_1_x1 = [mean_intensity_1[0]] \n",
    "X_validation_1_x2 = [mean_intensity_1[1]] \n",
    "X_validation_1_x3 = [mean_intensity_1[2]] \n",
    "X_validation_1_x4 = [mean_intensity_1[3]] \n",
    "X_validation_1_x5 = [mean_intensity_1[4]] \n",
    "X_validation_1_x6 = [mean_intensity_1[5]] \n",
    "X_validation_1_x7 = [mean_intensity_1[6]] \n",
    "X_validation_1_x8 = [mean_intensity_1[7]] \n",
    "\n",
    "\n",
    "\n",
    "Y_validation_1_y1  =[y_train_1[0]] \n",
    "Y_validation_1_y2 = [y_train_1[1]] \n",
    "Y_validation_1_y3 = [y_train_1[2]] \n",
    "Y_validation_1_y4 = [y_train_1[3]] \n",
    "Y_validation_1_y5 = [y_train_1[4]] \n",
    "Y_validation_1_y6 = [y_train_1[5]] \n",
    "Y_validation_1_y7 = [y_train_1[6]] \n",
    "Y_validation_1_y8 = [y_train_1[7]] \n",
    "\n",
    "\n",
    "X_validation_1 = np.concatenate([\n",
    "                    np.array(X_validation_1_x1).reshape(-1,1), \n",
    "                    np.array(X_validation_1_x2).reshape(-1,1),\n",
    "                    np.array(X_validation_1_x3).reshape(-1,1),\n",
    "                    np.array(X_validation_1_x4).reshape(-1,1),\n",
    "                    #np.array(X_validation_1_x5).reshape(-1,1),\n",
    "                    np.array(X_validation_1_x6).reshape(-1,1)\n",
    "                    #np.array(X_validation_1_x7).reshape(-1,1),\n",
    "                    #np.array(X_validation_1_x8).reshape(-1,1)\n",
    "                    ])\n",
    "\n",
    "\n",
    "\n",
    "Y_validation_1 = np.concatenate([\n",
    "                    np.array(Y_validation_1_y1).reshape(-1,1), \n",
    "                    np.array(Y_validation_1_y2).reshape(-1,1),\n",
    "                    np.array(Y_validation_1_y3).reshape(-1,1),\n",
    "                    np.array(Y_validation_1_y4).reshape(-1,1),\n",
    "                    #np.array(Y_validation_1_y5).reshape(-1,1),\n",
    "                    np.array(Y_validation_1_y6).reshape(-1,1)\n",
    "                    #np.array(Y_validation_1_y7).reshape(-1,1),\n",
    "                    #np.array(Y_validation_1_y8).reshape(-1,1)\n",
    "                    ])\n",
    "\n",
    "Y_validationall_1 = np.concatenate([\n",
    "                    np.array(Y_validation_1_y1).reshape(-1,1), \n",
    "                    np.array(Y_validation_1_y2).reshape(-1,1),\n",
    "                    np.array(Y_validation_1_y3).reshape(-1,1),\n",
    "                    np.array(Y_validation_1_y4).reshape(-1,1),\n",
    "                    np.array(Y_validation_1_y5).reshape(-1,1),\n",
    "                    np.array(Y_validation_1_y6).reshape(-1,1),\n",
    "                    np.array(Y_validation_1_y7).reshape(-1,1),\n",
    "                    np.array(Y_validation_1_y8).reshape(-1,1)\n",
    "                    ])\n",
    "\n",
    "\n",
    "\n",
    "Y_predicted_1 = model_1.predict(X_validation_1)\n",
    "\n",
    "Y_predicted_1_a = np.std(model_1.predict(np.array(X_train_2[1]).reshape(-1,1)))\n",
    "Y_predicted_1_b = np.std(model_1.predict(np.array(X_train_2[3]).reshape(-1,1)))\n",
    "\n",
    "\n",
    "r2_val_1 = r2_score(Y_validation_1, Y_predicted_1)\n",
    "rmse_val_1 = np.sqrt(mean_squared_error(Y_validation_1, Y_predicted_1))\n",
    "\n",
    "print('R2: ' + str(r2_val_1))\n",
    "print('RMSE: '+ str(rmse_val_1))\n",
    "\n",
    "###############################################################\n",
    "\n",
    "plt_4.figure(figsize=(8, 5))\n",
    "#plt_4.scatter(Y_validation_1, Y_predicted_1, color='black', label='Predicted vs Actual')\n",
    "\n",
    "plt_4.errorbar(Y_validation_1[0], Y_predicted_1[0]  , yerr=Y_predicted_1_a, fmt='o', color='orange', ecolor='black', capsize=3,label='SAMPLE 2')\n",
    "plt_4.errorbar(Y_validation_1[1], Y_predicted_1[1]  , yerr=Y_predicted_1_b, fmt='o', color='red', ecolor='black', capsize=3,label='SAMPLE 4')\n",
    "\n",
    "# Plot the 45-degree line (y=x) for reference\n",
    "\n",
    "plt_4.plot([min(Y_validationall_1), max(Y_validationall_1)], \n",
    "         [min(Y_validationall_1), max(Y_validationall_1)], \n",
    "         color='red', linestyle='--')\n",
    "\n",
    "title_4 = (Element_name) + ' ' + (Peak_Pos)+ ' - BATCH 2 - VALIDATION RESULTS'\n",
    "\n",
    "# Add labels and title\n",
    "plt_4.xlabel('Actual Concentration (%)')\n",
    "plt_4.ylabel('Predicted Concentration (%)')\n",
    "plt_4.title(title_4)\n",
    "plt_4.legend(bbox_to_anchor=(1, 1), loc='upper left')\n",
    "\n",
    "\n",
    "plt_4.text(0.92,0.05, f'R^2 = {r2_val_1:.4f}\\nRMSE = {rmse_val_1:.4f}', transform=plt.gcf().transFigure, fontsize=10)\n",
    "plt_4.savefig((title_4)+ \".png\" ,dpi = 1200 , bbox_inches='tight')\n",
    "\n",
    "plt_4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37e4333-a6ce-46bb-b6d7-7d8a9a8b00be",
   "metadata": {},
   "source": [
    "# BATCH 3 - CALIBRATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5373f84c-e81c-45c0-af91-3b5880c75443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt_2\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "# Flatten X_train to fit the model\n",
    "mean_intensity_2 = np.array([np.mean(sample_2) for sample_2 in X_train_2])\n",
    "std_dev_intensity_2 = np.array([np.std(sample_2) for sample_2 in X_train_2])\n",
    "\n",
    "X_flattened_2_x9 =  [mean_intensity_2[0]] \n",
    "X_flattened_2_x10 = [mean_intensity_2[1]] \n",
    "X_flattened_2_x11 = [mean_intensity_2[2]] \n",
    "X_flattened_2_x12 = [mean_intensity_2[3]] \n",
    "X_flattened_2_x13 = [mean_intensity_2[4]] \n",
    "X_flattened_2_x14 = [mean_intensity_2[5]] \n",
    "X_flattened_2_x15 = [mean_intensity_2[6]] \n",
    "X_flattened_2_x16 = [mean_intensity_2[7]] \n",
    "X_flattened_2_x17 = [mean_intensity_2[8]] \n",
    "\n",
    "\n",
    "\n",
    "Y_flattened_2_y9  = [y_train_2[0]] \n",
    "Y_flattened_2_y10 = [y_train_2[1]] \n",
    "Y_flattened_2_y11 = [y_train_2[2]] \n",
    "Y_flattened_2_y12 = [y_train_2[3]] \n",
    "Y_flattened_2_y13 = [y_train_2[4]] \n",
    "Y_flattened_2_y14 = [y_train_2[5]] \n",
    "Y_flattened_2_y15 = [y_train_2[6]] \n",
    "Y_flattened_2_y16 = [y_train_2[7]] \n",
    "Y_flattened_2_y17 = [y_train_2[8]] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_flattened_2 = np.concatenate([\n",
    "                    np.array(X_flattened_2_x9).reshape(-1,1), \n",
    "                    np.array(X_flattened_2_x10).reshape(-1,1),\n",
    "                    np.array(X_flattened_2_x11).reshape(-1,1),\n",
    "                    np.array(X_flattened_2_x12).reshape(-1,1),\n",
    "                    np.array(X_flattened_2_x13).reshape(-1,1),\n",
    "                    np.array(X_flattened_2_x14).reshape(-1,1),\n",
    "                    np.array(X_flattened_2_x15).reshape(-1,1),\n",
    "                    np.array(X_flattened_2_x16).reshape(-1,1),\n",
    "                    np.array(X_flattened_2_x17).reshape(-1,1)\n",
    "                    ])\n",
    "\n",
    "Y_flattened_2 = np.concatenate([\n",
    "                    np.array(Y_flattened_2_y9).reshape(-1,1), \n",
    "                    np.array(Y_flattened_2_y10).reshape(-1,1),\n",
    "                    np.array(Y_flattened_2_y11).reshape(-1,1),\n",
    "                    np.array(Y_flattened_2_y12).reshape(-1,1),\n",
    "                    np.array(Y_flattened_2_y13).reshape(-1,1),\n",
    "                    np.array(Y_flattened_2_y14).reshape(-1,1),\n",
    "                    np.array(Y_flattened_2_y15).reshape(-1,1),\n",
    "                    np.array(Y_flattened_2_y16).reshape(-1,1),\n",
    "                    np.array(Y_flattened_2_y17).reshape(-1,1)\n",
    "                    ])\n",
    "\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "model_2 = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "model_2.fit(X_flattened_2, Y_flattened_2)\n",
    "\n",
    "\n",
    "\n",
    "# Compute R2 and RMSE\n",
    "r2_2 = model_2.score(X_flattened_2,Y_flattened_2)\n",
    "rmse_2 = np.sqrt(mean_squared_error(X_flattened_2,Y_flattened_2))\n",
    "\n",
    "# Get the model coefficients and intercept\n",
    "coefficients_2 = model_2.coef_\n",
    "intercept_2 = model_2.intercept_\n",
    "\n",
    "print((coefficients_2 * X_flattened_2_x14) + intercept_2)\n",
    "    \n",
    "# # Plotting with horizontal error bars\n",
    "plt_2.figure(figsize=(8, 5))\n",
    "\n",
    "plt_2.errorbar(X_flattened_2_x9, Y_flattened_2_y9  , xerr=std_dev_intensity_2[0], fmt='o', color='olive', ecolor='black', capsize=3,label='SAMPLE 9')\n",
    "plt_2.errorbar(X_flattened_2_x10,Y_flattened_2_y10 , xerr=std_dev_intensity_2[1], fmt='o', color='cyan', ecolor='black', capsize=3,label='SAMPLE 10')\n",
    "plt_2.errorbar(X_flattened_2_x11,Y_flattened_2_y11 , xerr=std_dev_intensity_2[2], fmt='o', color='black', ecolor='black', capsize=3,label='SAMPLE 11')\n",
    "plt_2.errorbar(X_flattened_2_x12,Y_flattened_2_y12 , xerr=std_dev_intensity_2[3], fmt='o', color='tomato', ecolor='black', capsize=3,label='SAMPLE 12')\n",
    "plt_2.errorbar(X_flattened_2_x13,Y_flattened_2_y13 , xerr=std_dev_intensity_2[4], fmt='o', color='steelblue', ecolor='black', capsize=3,label='SAMPLE 13')\n",
    "plt_2.errorbar(X_flattened_2_x14,Y_flattened_2_y14 , xerr=std_dev_intensity_2[5], fmt='o', color='limegreen', ecolor='black', capsize=3,label='SAMPLE 14')\n",
    "plt_2.errorbar(X_flattened_2_x15,Y_flattened_2_y15 , xerr=std_dev_intensity_2[6], fmt='o', color='deeppink', ecolor='black', capsize=3,label='SAMPLE 15')\n",
    "plt_2.errorbar(X_flattened_2_x16,Y_flattened_2_y16 , xerr=std_dev_intensity_2[7], fmt='o', color='gold', ecolor='black', capsize=3,label='SAMPLE 16')\n",
    "plt_2.errorbar(X_flattened_2_x17,Y_flattened_2_y17 , xerr=std_dev_intensity_2[8], fmt='o', color='indigo', ecolor='black', capsize=3,label='SAMPLE 17')\n",
    "\n",
    "\n",
    "plt_2.plot(X_flattened_2,model_2.predict(X_flattened_2), color ='black' , linewidth = 0.5)\n",
    "\n",
    "\n",
    "title_2 = (Element_name) + ' ' + (Peak_Pos)+ ' - BATCH 3 REFERENCE'\n",
    "plt_2.xlabel('Intensities (a.u.)')\n",
    "plt_2.ylabel('Concentration (%) ')\n",
    "plt_2.title(title_2)\n",
    "plt_2.legend(bbox_to_anchor=(1, 1), loc='upper left')\n",
    "\n",
    "plt_2.text(0.85, 0.9, f'y = {coefficients_2:}x + {intercept_2:}', transform=plt.gcf().transFigure, fontsize=10)\n",
    "plt_2.text(0.92,0.05, f'R^2 = {r2_2:.2f}\\nRMSE = {rmse_2:.2f}', transform=plt.gcf().transFigure, fontsize=10)\n",
    "# plt_2.savefig((title_2)+ \".png\" ,dpi = 1200 , bbox_inches='tight')\n",
    "\n",
    "plt_2.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e76844-4a50-4dbc-842d-019d787d9d53",
   "metadata": {},
   "source": [
    "# BATCH 3 VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e14f00d-42ae-407e-a6a3-cf708f4d6892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt_5\n",
    "\n",
    "\n",
    "X_validation_2_x9 =  [mean_intensity_2[0]] \n",
    "X_validation_2_x10 = [mean_intensity_2[1]] \n",
    "X_validation_2_x11 = [mean_intensity_2[2]] \n",
    "X_validation_2_x12 = [mean_intensity_2[3]] \n",
    "X_validation_2_x13 = [mean_intensity_2[4]] \n",
    "X_validation_2_x14 = [mean_intensity_2[5]] \n",
    "X_validation_2_x15 = [mean_intensity_2[6]] \n",
    "X_validation_2_x16 = [mean_intensity_2[7]] \n",
    "X_validation_2_x17 = [mean_intensity_2[8]] \n",
    "\n",
    "Y_validation_2_y9  = [y_train_2[0]] \n",
    "Y_validation_2_y10 = [y_train_2[1]] \n",
    "Y_validation_2_y11 = [y_train_2[2]] \n",
    "Y_validation_2_y12 = [y_train_2[3]] \n",
    "Y_validation_2_y13 = [y_train_2[4]] \n",
    "Y_validation_2_y14 = [y_train_2[5]] \n",
    "Y_validation_2_y15 = [y_train_2[6]] \n",
    "Y_validation_2_y16 = [y_train_2[7]] \n",
    "Y_validation_2_y17 = [y_train_2[8]] \n",
    "\n",
    "\n",
    "X_validation_2 = np.concatenate([\n",
    "                    np.array(X_validation_2_x9).reshape(-1,1), \n",
    "                    np.array(X_validation_2_x10).reshape(-1,1),\n",
    "                    np.array(X_validation_2_x11).reshape(-1,1),\n",
    "                    #np.array(X_validation_2_x12).reshape(-1,1),\n",
    "                    np.array(X_validation_2_x13).reshape(-1,1),\n",
    "                    #np.array(X_validation_2_x14).reshape(-1,1),\n",
    "                    #np.array(X_validation_2_x15).reshape(-1,1),\n",
    "                    #np.array(X_validation_2_x16).reshape(-1,1),\n",
    "                    np.array(X_validation_2_x17).reshape(-1,1)\n",
    "                    ])\n",
    "Y_validation_2 = np.concatenate([\n",
    "                    np.array(Y_validation_2_y9).reshape(-1,1), \n",
    "                    np.array(Y_validation_2_y10).reshape(-1,1),\n",
    "                    np.array(Y_validation_2_y11).reshape(-1,1),\n",
    "                    #np.array(Y_validation_2_y12).reshape(-1,1),\n",
    "                    np.array(Y_validation_2_y13).reshape(-1,1),\n",
    "                    #np.array(Y_validation_2_y14).reshape(-1,1),\n",
    "                    #np.array(Y_validation_2_y15).reshape(-1,1),\n",
    "                    #np.array(Y_validation_2_y16).reshape(-1,1),\n",
    "                    np.array(Y_validation_2_y17).reshape(-1,1)\n",
    "                    ])\n",
    "\n",
    "Y_validationall_2 = np.concatenate([\n",
    "                    np.array(Y_validation_2_y9).reshape(-1,1), \n",
    "                    np.array(Y_validation_2_y10).reshape(-1,1),\n",
    "                    np.array(Y_validation_2_y11).reshape(-1,1),\n",
    "                    np.array(Y_validation_2_y12).reshape(-1,1),\n",
    "                    np.array(Y_validation_2_y13).reshape(-1,1),\n",
    "                    np.array(Y_validation_2_y14).reshape(-1,1),\n",
    "                    np.array(Y_validation_2_y15).reshape(-1,1),\n",
    "                    np.array(Y_validation_2_y16).reshape(-1,1),\n",
    "                    np.array(Y_validation_2_y17).reshape(-1,1)\n",
    "                    ])\n",
    "\n",
    "Y_predicted_2 = model_2.predict(X_validation_2)\n",
    "\n",
    "Y_predicted_2_a = np.std(model_2.predict(np.array(X_train_2[1]).reshape(-1,1)))\n",
    "Y_predicted_2_b = np.std(model_2.predict(np.array(X_train_2[5]).reshape(-1,1)))\n",
    "\n",
    "\n",
    "r2_val_2 = r2_score(Y_validation_2, Y_predicted_2)\n",
    "rmse_val_2 = np.sqrt(mean_squared_error(Y_validation_2, Y_predicted_2))\n",
    "\n",
    "\n",
    "print('R2: ' + str(r2_val_2))\n",
    "print('RMSE: '+ str(rmse_val_2))\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "plt_5.figure(figsize=(8, 5))\n",
    "\n",
    "plt_5.errorbar(Y_validation_2[0], Y_predicted_2[0]  , yerr=Y_predicted_2_a, fmt='o', color='cyan', ecolor='black', capsize=3,label='SAMPLE 10')\n",
    "plt_5.errorbar(Y_validation_2[1], Y_predicted_2[1]  , yerr=Y_predicted_2_b, fmt='o', color='limegreen', ecolor='black', capsize=3,label='SAMPLE 14')\n",
    "\n",
    "\n",
    "# Plot the 45-degree line (y=x) for reference\n",
    "plt_5.plot([min(Y_validationall_2), max(Y_validationall_2)], \n",
    "         [min(Y_validationall_2), max(Y_validationall_2)], \n",
    "         color='red', linestyle='--')\n",
    "\n",
    "title_5 = (Element_name) + ' ' + (Peak_Pos)+ ' - BATCH 3 - VALIDATION RESULTS'\n",
    "\n",
    "# Add labels and title\n",
    "plt_5.xlabel('Actual Concentration (%)')\n",
    "plt_5.ylabel('Predicted Concentration(%)')\n",
    "plt_5.title(title_5)\n",
    "plt_5.legend(bbox_to_anchor=(1, 1), loc='upper left')\n",
    "\n",
    "plt_5.text(0.92,0.05, f'R^2 = {r2_val_2:.4f}\\nRMSE = {rmse_val_2:.4f}', transform=plt.gcf().transFigure, fontsize=10)\n",
    "\n",
    "# plt_5.savefig((title_5)+ \".png\" ,dpi = 1200 , bbox_inches='tight')\n",
    "\n",
    "plt_5.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ae1388-1a76-45c0-9416-14818f69b607",
   "metadata": {},
   "source": [
    "# BATCH 2 and 3 - CALIBRATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b2cd4b-2f6b-409f-9bd6-2a75f0251ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt_3\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "# Flatten X_train to fit the model\n",
    "mean_intensity_3 = np.array([np.mean(sample_3) for sample_3 in X_train_3])\n",
    "std_dev_intensity_3 = np.array([np.std(sample_3) for sample_3 in X_train_3])\n",
    "\n",
    "\n",
    "X_flattened_3_x1 =  [mean_intensity_3[0]] \n",
    "X_flattened_3_x2 =  [mean_intensity_3[1]] \n",
    "X_flattened_3_x3 =  [mean_intensity_3[2]] \n",
    "X_flattened_3_x4 =  [mean_intensity_3[3]] \n",
    "X_flattened_3_x5 =  [mean_intensity_3[4]] \n",
    "X_flattened_3_x6 =  [mean_intensity_3[5]] \n",
    "X_flattened_3_x7 =  [mean_intensity_3[6]] \n",
    "X_flattened_3_x8 =  [mean_intensity_3[7]] \n",
    "X_flattened_3_x9 =  [mean_intensity_3[8]] \n",
    "X_flattened_3_x10 = [mean_intensity_3[9]] \n",
    "X_flattened_3_x11 = [mean_intensity_3[10]] \n",
    "X_flattened_3_x12 = [mean_intensity_3[11]] \n",
    "X_flattened_3_x13 = [mean_intensity_3[12]] \n",
    "X_flattened_3_x14 = [mean_intensity_3[13]] \n",
    "X_flattened_3_x15 = [mean_intensity_3[14]] \n",
    "X_flattened_3_x16 = [mean_intensity_3[15]] \n",
    "X_flattened_3_x17 = [mean_intensity_3[16]] \n",
    "\n",
    "\n",
    "Y_flattened_3_y1  = [y_train_3[0]] \n",
    "Y_flattened_3_y2 =  [y_train_3[1]] \n",
    "Y_flattened_3_y3 =  [y_train_3[2]] \n",
    "Y_flattened_3_y4 =  [y_train_3[3]] \n",
    "Y_flattened_3_y5 =  [y_train_3[4]] \n",
    "Y_flattened_3_y6 =  [y_train_3[5]] \n",
    "Y_flattened_3_y7 =  [y_train_3[6]] \n",
    "Y_flattened_3_y8 =  [y_train_3[7]] \n",
    "Y_flattened_3_y9  = [y_train_3[8]] \n",
    "Y_flattened_3_y10 = [y_train_3[9]] \n",
    "Y_flattened_3_y11 = [y_train_3[10]] \n",
    "Y_flattened_3_y12 = [y_train_3[11]] \n",
    "Y_flattened_3_y13 = [y_train_3[12]] \n",
    "Y_flattened_3_y14 = [y_train_3[13]] \n",
    "Y_flattened_3_y15 = [y_train_3[14]] \n",
    "Y_flattened_3_y16 = [y_train_3[15]] \n",
    "Y_flattened_3_y17 = [y_train_3[16]] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_flattened_3 = np.concatenate([\n",
    "                    np.array(X_flattened_3_x1).reshape(-1,1),\n",
    "                    np.array(X_flattened_3_x2).reshape(-1,1), \n",
    "                    np.array(X_flattened_3_x3).reshape(-1,1), \n",
    "                    np.array(X_flattened_3_x4).reshape(-1,1), \n",
    "                    np.array(X_flattened_3_x5).reshape(-1,1), \n",
    "                    np.array(X_flattened_3_x6).reshape(-1,1),\n",
    "                    np.array(X_flattened_3_x7).reshape(-1,1), \n",
    "                    np.array(X_flattened_3_x8).reshape(-1,1), \n",
    "                    np.array(X_flattened_3_x9).reshape(-1,1), \n",
    "                    np.array(X_flattened_3_x10).reshape(-1,1),\n",
    "                    np.array(X_flattened_3_x11).reshape(-1,1),\n",
    "                    np.array(X_flattened_3_x12).reshape(-1,1),\n",
    "                    np.array(X_flattened_3_x13).reshape(-1,1),\n",
    "                    np.array(X_flattened_3_x14).reshape(-1,1),\n",
    "                    np.array(X_flattened_3_x15).reshape(-1,1),\n",
    "                    np.array(X_flattened_3_x16).reshape(-1,1),\n",
    "                    np.array(X_flattened_3_x17).reshape(-1,1)\n",
    "                    ])\n",
    "\n",
    "Y_flattened_3 = np.concatenate([\n",
    "                    np.array(Y_flattened_3_y1).reshape(-1,1), \n",
    "                    np.array(Y_flattened_3_y2).reshape(-1,1),\n",
    "                    np.array(Y_flattened_3_y3).reshape(-1,1),\n",
    "                    np.array(Y_flattened_3_y4).reshape(-1,1),\n",
    "                    np.array(Y_flattened_3_y5).reshape(-1,1),\n",
    "                    np.array(Y_flattened_3_y6).reshape(-1,1),\n",
    "                    np.array(Y_flattened_3_y7).reshape(-1,1),\n",
    "                    np.array(Y_flattened_3_y8).reshape(-1,1),\n",
    "                    np.array(Y_flattened_3_y9).reshape(-1,1), \n",
    "                    np.array(Y_flattened_3_y10).reshape(-1,1),\n",
    "                    np.array(Y_flattened_3_y11).reshape(-1,1),\n",
    "                    np.array(Y_flattened_3_y12).reshape(-1,1),\n",
    "                    np.array(Y_flattened_3_y13).reshape(-1,1),\n",
    "                    np.array(Y_flattened_3_y14).reshape(-1,1),\n",
    "                    np.array(Y_flattened_3_y15).reshape(-1,1),\n",
    "                    np.array(Y_flattened_3_y16).reshape(-1,1),\n",
    "                    np.array(Y_flattened_3_y17).reshape(-1,1)\n",
    "                    ])\n",
    "\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "model_3 = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "model_3.fit(X_flattened_3, Y_flattened_3)\n",
    "\n",
    "# Compute R2 and RMSE\n",
    "r2_3 = model_3.score(X_flattened_3,Y_flattened_3)\n",
    "rmse_3 = np.sqrt(mean_squared_error(X_flattened_3,Y_flattened_3))\n",
    "\n",
    "# Get the model coefficients and intercept\n",
    "coefficients_3 = model_3.coef_\n",
    "intercept_3 = model_3.intercept_\n",
    "\n",
    "print(coefficients_3)\n",
    "\n",
    "\n",
    "# # Plotting with horizontal error bars\n",
    "plt_3.figure(figsize=(8, 5))\n",
    "\n",
    "plt_3.errorbar(X_flattened_3_x1,  Y_flattened_3_y1 ,  xerr=std_dev_intensity_3[0], fmt='o', color='blue', ecolor='black', capsize=3,label='SAMPLE 1')\n",
    "plt_3.errorbar(X_flattened_3_x2,  Y_flattened_3_y2 ,  xerr=std_dev_intensity_3[1], fmt='o', color='orange', ecolor='black', capsize=3,label='SAMPLE 2')\n",
    "plt_3.errorbar(X_flattened_3_x3,  Y_flattened_3_y3 ,  xerr=std_dev_intensity_3[2], fmt='o', color='green', ecolor='black', capsize=3,label='SAMPLE 3')\n",
    "plt_3.errorbar(X_flattened_3_x4,  Y_flattened_3_y4 ,  xerr=std_dev_intensity_3[3], fmt='o', color='red', ecolor='black', capsize=3,label='SAMPLE 4')\n",
    "plt_3.errorbar(X_flattened_3_x5,  Y_flattened_3_y5 ,  xerr=std_dev_intensity_3[4], fmt='o', color='purple', ecolor='black', capsize=3,label='SAMPLE 5')\n",
    "plt_3.errorbar(X_flattened_3_x6,  Y_flattened_3_y6 ,  xerr=std_dev_intensity_3[5], fmt='o', color='brown', ecolor='black', capsize=3,label='SAMPLE 6')\n",
    "plt_3.errorbar(X_flattened_3_x7,  Y_flattened_3_y7 ,  xerr=std_dev_intensity_3[6], fmt='o', color='pink', ecolor='black', capsize=3,label='SAMPLE 7')\n",
    "plt_3.errorbar(X_flattened_3_x8,  Y_flattened_3_y8 ,  xerr=std_dev_intensity_3[7], fmt='o', color='gray', ecolor='black', capsize=3,label='SAMPLE 8')\n",
    "plt_3.errorbar(X_flattened_3_x9,  Y_flattened_3_y9 ,  xerr=std_dev_intensity_3[8], fmt='o', color='olive', ecolor='black', capsize=3,label='SAMPLE 9')\n",
    "plt_3.errorbar(X_flattened_3_x10, Y_flattened_3_y10 , xerr=std_dev_intensity_3[9], fmt='o', color='cyan', ecolor='black', capsize=3,label='SAMPLE 10')\n",
    "plt_3.errorbar(X_flattened_3_x11, Y_flattened_3_y11 , xerr=std_dev_intensity_3[10], fmt='o', color='black', ecolor='black', capsize=3,label='SAMPLE 11')\n",
    "plt_3.errorbar(X_flattened_3_x12, Y_flattened_3_y12 , xerr=std_dev_intensity_3[11], fmt='o', color='tomato', ecolor='black', capsize=3,label='SAMPLE 12')\n",
    "plt_3.errorbar(X_flattened_3_x13, Y_flattened_3_y13 , xerr=std_dev_intensity_3[12], fmt='o', color='steelblue', ecolor='black', capsize=3,label='SAMPLE 13')\n",
    "plt_3.errorbar(X_flattened_3_x14, Y_flattened_3_y14 , xerr=std_dev_intensity_3[13], fmt='o', color='limegreen', ecolor='black', capsize=3,label='SAMPLE 14')\n",
    "plt_3.errorbar(X_flattened_3_x15, Y_flattened_3_y15 , xerr=std_dev_intensity_3[14], fmt='o', color='deeppink', ecolor='black', capsize=3,label='SAMPLE 15')\n",
    "plt_3.errorbar(X_flattened_3_x16, Y_flattened_3_y16 , xerr=std_dev_intensity_3[15], fmt='o', color='gold', ecolor='black', capsize=3,label='SAMPLE 16')\n",
    "plt_3.errorbar(X_flattened_3_x17, Y_flattened_3_y17 , xerr=std_dev_intensity_3[16], fmt='o', color='indigo', ecolor='black', capsize=3,label='SAMPLE 17')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt_3.plot(X_flattened_3,model_3.predict(X_flattened_3), color ='black' , linewidth = 0.5)\n",
    "\n",
    "\n",
    "title_3 = (Element_name) + ' ' + (Peak_Pos)+ ' - BATCH 2 & 3 REFERENCE'\n",
    "plt_3.xlabel('Intensities (a.u.)')\n",
    "plt_3.ylabel('Concentration (%) ')\n",
    "plt_3.title(title_3)\n",
    "plt_3.legend(bbox_to_anchor=(1, 1), loc='upper left')\n",
    "\n",
    "plt_3.text(0.85, 0.9, f'y = {coefficients_3:}x + {intercept_3:}', transform=plt.gcf().transFigure, fontsize=10)\n",
    "plt_3.text(0.92,0.05, f'R^2 = {r2_3:.2f}\\nRMSE = {rmse_3:.2f}', transform=plt.gcf().transFigure, fontsize=10)\n",
    "plt_3.savefig((title_3)+ \".png\" ,dpi = 1200 , bbox_inches='tight')\n",
    "\n",
    "plt_3.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c304fa9-884f-474a-972a-fac5b0cdde0a",
   "metadata": {},
   "source": [
    "# BATCH 2 and BATCH 3 Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ec2ace-a1d6-40ce-bf13-7ac520ba7ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt_6\n",
    "\n",
    "\n",
    "X_validation_3_x1 =  [mean_intensity_3[0]] \n",
    "X_validation_3_x2 =  [mean_intensity_3[1]] \n",
    "X_validation_3_x3 =  [mean_intensity_3[2]] \n",
    "X_validation_3_x4 =  [mean_intensity_3[3]] \n",
    "X_validation_3_x5 =  [mean_intensity_3[4]] \n",
    "X_validation_3_x6 =  [mean_intensity_3[5]] \n",
    "X_validation_3_x7 =  [mean_intensity_3[6]] \n",
    "X_validation_3_x8 =  [mean_intensity_3[7]] \n",
    "X_validation_3_x9 =  [mean_intensity_3[8]] \n",
    "X_validation_3_x10 = [mean_intensity_3[9]] \n",
    "X_validation_3_x11 = [mean_intensity_3[10]] \n",
    "X_validation_3_x12 = [mean_intensity_3[11]] \n",
    "X_validation_3_x13 = [mean_intensity_3[12]] \n",
    "X_validation_3_x14 = [mean_intensity_3[13]] \n",
    "X_validation_3_x15 = [mean_intensity_3[14]] \n",
    "X_validation_3_x16 = [mean_intensity_3[15]] \n",
    "X_validation_3_x17 = [mean_intensity_3[16]] \n",
    "\n",
    "\n",
    "Y_validation_3_y1  = [y_train_3[0]] \n",
    "Y_validation_3_y2 =  [y_train_3[1]] \n",
    "Y_validation_3_y3 =  [y_train_3[2]] \n",
    "Y_validation_3_y4 =  [y_train_3[3]] \n",
    "Y_validation_3_y5 =  [y_train_3[4]] \n",
    "Y_validation_3_y6 =  [y_train_3[5]] \n",
    "Y_validation_3_y7 =  [y_train_3[6]] \n",
    "Y_validation_3_y8 =  [y_train_3[7]] \n",
    "Y_validation_3_y9  = [y_train_3[8]] \n",
    "Y_validation_3_y10 = [y_train_3[9]] \n",
    "Y_validation_3_y11 = [y_train_3[10]] \n",
    "Y_validation_3_y12 = [y_train_3[11]] \n",
    "Y_validation_3_y13 = [y_train_3[12]] \n",
    "Y_validation_3_y14 = [y_train_3[13]] \n",
    "Y_validation_3_y15 = [y_train_3[14]] \n",
    "Y_validation_3_y16 = [y_train_3[15]] \n",
    "Y_validation_3_y17 = [y_train_3[16]] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_validation_3 = np.concatenate([\n",
    "                    np.array(X_validation_3_x1).reshape(-1,1),\n",
    "                    #np.array(X_validation_3_x2).reshape(-1,1), \n",
    "                    #np.array(X_validation_3_x3).reshape(-1,1), \n",
    "                    #np.array(X_validation_3_x4).reshape(-1,1), \n",
    "                    #np.array(X_validation_3_x5).reshape(-1,1), \n",
    "                    np.array(X_validation_3_x6).reshape(-1,1),\n",
    "                    #np.array(X_validation_3_x7).reshape(-1,1), \n",
    "                    #np.array(X_validation_3_x8).reshape(-1,1), \n",
    "                    #np.array(X_validation_3_x9).reshape(-1,1), \n",
    "                    np.array(X_validation_3_x10).reshape(-1,1)\n",
    "                    #np.array(X_validation_3_x11).reshape(-1,1),\n",
    "                    #np.array(X_validation_3_x12).reshape(-1,1),\n",
    "                    #np.array(X_validation_3_x13).reshape(-1,1),\n",
    "                    #np.array(X_validation_3_x14).reshape(-1,1),\n",
    "                    #np.array(X_validation_3_x15).reshape(-1,1),\n",
    "                    #np.array(X_validation_3_x16).reshape(-1,1)\n",
    "                    #np.array(X_validation_3_x17).reshape(-1,1)\n",
    "                    ])\n",
    "\n",
    "Y_validation_3 = np.concatenate([\n",
    "                    np.array(Y_validation_3_y1).reshape(-1,1), \n",
    "                    #np.array(Y_validation_3_y2).reshape(-1,1),\n",
    "                    #np.array(Y_validation_3_y3).reshape(-1,1),\n",
    "                    #np.array(Y_validation_3_y4).reshape(-1,1),\n",
    "                    #np.array(Y_validation_3_y5).reshape(-1,1),\n",
    "                    np.array(Y_validation_3_y6).reshape(-1,1),\n",
    "                    #np.array(Y_validation_3_y7).reshape(-1,1),\n",
    "                    #np.array(Y_validation_3_y8).reshape(-1,1),\n",
    "                    #np.array(Y_validation_3_y9).reshape(-1,1), \n",
    "                    np.array(Y_validation_3_y10).reshape(-1,1)\n",
    "                    #np.array(Y_validation_3_y11).reshape(-1,1),\n",
    "                    #np.array(Y_validation_3_y12).reshape(-1,1),\n",
    "                    #np.array(Y_validation_3_y13).reshape(-1,1),\n",
    "                    #np.array(Y_validation_3_y14).reshape(-1,1),\n",
    "                    #np.array(Y_validation_3_y15).reshape(-1,1),\n",
    "                    #np.array(Y_validation_3_y16).reshape(-1,1)\n",
    "                    #np.array(Y_validation_3_y17).reshape(-1,1)\n",
    "                    ])\n",
    "\n",
    "Y_validationall_3 = np.concatenate([\n",
    "                    np.array(Y_validation_3_y1).reshape(-1,1), \n",
    "                    np.array(Y_validation_3_y2).reshape(-1,1),\n",
    "                    np.array(Y_validation_3_y3).reshape(-1,1),\n",
    "                    np.array(Y_validation_3_y4).reshape(-1,1),\n",
    "                    np.array(Y_validation_3_y5).reshape(-1,1),\n",
    "                    np.array(Y_validation_3_y6).reshape(-1,1),\n",
    "                    np.array(Y_validation_3_y7).reshape(-1,1),\n",
    "                    np.array(Y_validation_3_y8).reshape(-1,1),\n",
    "                    np.array(Y_validation_3_y9).reshape(-1,1), \n",
    "                    np.array(Y_validation_3_y10).reshape(-1,1),\n",
    "                    np.array(Y_validation_3_y11).reshape(-1,1),\n",
    "                    np.array(Y_validation_3_y12).reshape(-1,1),\n",
    "                    np.array(Y_validation_3_y13).reshape(-1,1),\n",
    "                    np.array(Y_validation_3_y14).reshape(-1,1),\n",
    "                    np.array(Y_validation_3_y15).reshape(-1,1),\n",
    "                    np.array(Y_validation_3_y16).reshape(-1,1),\n",
    "                    np.array(Y_validation_3_y17).reshape(-1,1)\n",
    "                    ])\n",
    "\n",
    "\n",
    "Y_predicted_3 = model_3.predict(X_validation_3)\n",
    "\n",
    "Y_predicted_3_a = np.std(model_3.predict(np.array(X_train_3[0]).reshape(-1,1)))\n",
    "Y_predicted_3_b = np.std(model_3.predict(np.array(X_train_3[5]).reshape(-1,1)))\n",
    "Y_predicted_3_c = np.std(model_3.predict(np.array(X_train_3[9]).reshape(-1,1)))\n",
    "\n",
    "\n",
    "\n",
    "r2_val_3 = r2_score(Y_validation_3, Y_predicted_3)\n",
    "rmse_val_3 = np.sqrt(mean_squared_error(Y_validation_3, Y_predicted_3))\n",
    "\n",
    "print('R2: ' + str(r2_val_3))\n",
    "print('RMSE: '+ str(rmse_val_3))\n",
    "\n",
    "######################################################\n",
    "\n",
    "plt_6.figure(figsize=(8, 5))\n",
    "# plt_6.scatter(Y_validation_3, Y_predicted_3, color='black', label='Predicted vs Actual')\n",
    "\n",
    "\n",
    "plt_6.errorbar(Y_validation_3[0], Y_predicted_3[0]  , yerr=Y_predicted_3_a, fmt='o', color='blue', ecolor='black', capsize=3,label='SAMPLE 1')\n",
    "plt_6.errorbar(Y_validation_3[1], Y_predicted_3[1]  , yerr=Y_predicted_3_b, fmt='o', color='brown', ecolor='black', capsize=3,label='SAMPLE 6')\n",
    "plt_6.errorbar(Y_validation_3[2], Y_predicted_3[2]  , yerr=Y_predicted_3_c, fmt='o', color='cyan', ecolor='black', capsize=3,label='SAMPLE 10')\n",
    "\n",
    "print(Y_validation_3[2])\n",
    "\n",
    "# Plot the 45-degree line (y=x) for reference\n",
    "plt_6.plot([min(Y_validationall_3), max(Y_validationall_3)], \n",
    "         [min(Y_validationall_3), max(Y_validationall_3)], \n",
    "         color='red', linestyle='--')\n",
    "\n",
    "title_6 = (Element_name) + ' ' + (Peak_Pos)+ ' - BATCH 2 & 3 - VALIDATION RESULTS'\n",
    "\n",
    "# Add labels and title\n",
    "plt_6.xlabel('Actual Concentration (%)')\n",
    "plt_6.ylabel('Predicted Concentration (%)')\n",
    "plt_6.title(title_6)\n",
    "plt_6.legend(bbox_to_anchor=(1, 1), loc='upper left')\n",
    "\n",
    "\n",
    "plt_6.text(0.92,0.05, f'R^2 = {r2_val_3:.4f}\\nRMSE = {rmse_val_3:.4f}', transform=plt.gcf().transFigure, fontsize=10)\n",
    "# plt_6.savefig((title_6)+ \".png\" ,dpi = 1200 , bbox_inches='tight')\n",
    "\n",
    "plt_6.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
